{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HollyJY/202406_sumSchool_neuroAI/blob/main/W2_Spike_Network_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFqDa9IafMeC"
      },
      "source": [
        "# In-Class Tutorial: Cell-Type Specific Cortical Microcircuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQTrTZ3Np9cs"
      },
      "source": [
        "Author(s): Yifan Luo\n",
        "\n",
        "Contact: yifan.luo@student.uva.nl\n",
        "\n",
        "This notebook is based on the work of:\n",
        "\n",
        "1) Potjans TC, Diesmann M. The cell-type specific cortical microcircuit: relating structure and activity in a full-scale spiking network model. Cereb Cortex. 2014 Mar;24(3):785-806. doi: 10.1093/cercor/bhs358. Epub 2012 Dec 2. PMID: 23203991; PMCID: PMC3920768.\n",
        "\n",
        "2) Original model implementation: https://github.com/ModelDBRepository/244261\n",
        "\n",
        "Please note that:\n",
        "\n",
        "1) Every practical excercise has its solution attached right after it. Do not hesitate to check it out when you feel stuck in a certain step ðŸ˜€;\n",
        "\n",
        "2) We encourage you to discuss the To Think questions with your classmates and/or TA. Although skipping those question won't affect the execution of code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recommended Hardware Accelerator**: CPU with high RAM (Colab Pro needed). If you are using local runtime, please ensure the **RAM is > 12 GB**.\n",
        "\n",
        "Free Colab CPU runtime is an viable option as well. Although the simulation would be a bit slower.\n",
        "\n",
        "**Estimated Time per Simulation (CPU runtime)**: ~22 min (initial simulation), ~9 min\n",
        "\n",
        "**Estimated Time per Simulation (High RAM runtime)**: ~10 min (initial simulation), ~3 min"
      ],
      "metadata": {
        "id": "uWanOXC9O8ig"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaRHmlxyjMuy"
      },
      "source": [
        "## 0. Preparations\n",
        "In this module, we will create a folder in your google drive to store all the code and data for this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLtPMl9JfK4z"
      },
      "outputs": [],
      "source": [
        "# make a 'spike_network' folder in your google drive to store the code and data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/spike_network', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xpt3AJtjsJu_"
      },
      "outputs": [],
      "source": [
        "# clone the github repository to spike_network\n",
        "# note: this repository is modified based on the original model implementation\n",
        "# for educational purposes of this tutorial\n",
        "!git clone https://github.com/Beckinetic/SpikeNetwork.git '/content/drive/MyDrive/spike_network'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kEeIjqvQ1Otz"
      },
      "outputs": [],
      "source": [
        "# move the working directory to spike_network\n",
        "%cd /content/drive/MyDrive/spike_network\n",
        "\n",
        "# pull the changes to ensure the repo is up to date\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YUFRZTmLrMu2"
      },
      "outputs": [],
      "source": [
        "# install required packages\n",
        "!pip install -r requirements.txt\n",
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUW-Ye91sKtl"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Use 'Agg' backend for rendering plots in scripts or servers without GUI\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as sc\n",
        "\n",
        "from brian2 import *\n",
        "\n",
        "warnings.filterwarnings('ignore')  # We are reckless!\n",
        "\n",
        "# brian2 is the most important package we are going to use. It is dedicated to\n",
        "# simulate spiking neural networks in python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcQTiFZmDJ6I"
      },
      "source": [
        "## 1. Building the Network\n",
        "Now we are all set with prerequisites and ready to simulate some networks! First, let's take a look at the illustration of the network we are going to simulate.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/Beckinetic/SpikeNetwork/master/images/network_structure.gif\" width=450></center>\n",
        "\n",
        "*Note.* Excitatory neurons (triangles) and inhibitory neurons (circles) are shown. Excitatory connections (black) and inhibitory connections (grey) with >.04 connectivity probability are shown.\n",
        "\n",
        "This network corresponds to a biological cortical network of the surface area of 1 mm$^2$. The network simulates 8 neuron populations: L2/3e (excitatory neurons in layer 2/3), L2/3i (inhibitory neurons in layer 2/3), L4e, L4i, L5e, L5i, L6e, L6i, and Th (thalamic neurons). The neurons in this network are connected with other neurons within the same layer or from other layers. This network also should be able to receive various forms external inputs so we can study the spontaneous and stimulus-evoked activities.\n",
        "\n",
        "To build this cortical model, we have a rough three-step plan:\n",
        "\n",
        "1. Define the single neuron model (LIF)\n",
        "2. Wire up the neurons to form a network\n",
        "3. Define the external input forms\n",
        "\n",
        "Let's get started with the LIF model!\n",
        "\n",
        "Our first step is to determine the model for every single neuron in this network. In this case, we adopt the **leaky integrate-and-fire model** (LIF) as the neuron model. To put it simply, in this model the neuron may receive inputs (currents) from synapses and external sources, and if the inputs are frequent enough to cause the membrane potential to reach a certain threshold, the neuron may fire a spike. A more detailed introduction could be found [here](https://neuronaldynamics.epfl.ch/online/Ch1.S3.html).\n",
        "\n",
        "<font color='red'>**To Think 1-1**</font>: Do you think the LIF model as the model for single neurons in spiking network serves the right level of model simplification? (Hint: compare it with Hodgkin-Huxley neurons and convolutional neural network neurons)\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/jeshraghian/snntorch/master/docs/_static/img/examples/tutorial2/2_1_neuronmodels.png\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75aAQlW39uMd"
      },
      "source": [
        "### LIF Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd5coIfg-xUL"
      },
      "source": [
        "The core bit of the LIF model is the input integrating equation (linear differential equation of membrane voltage):\n",
        "\n",
        "$${dv}/{dt} = (-v+v_{r})/{\\tau_m} + (I+I_{ext})/{C_m}$$\n",
        "\n",
        "This equation simulates the membrane voltage changing behavior, including how the voltage decays to resting potential and how it changes when there's external inputs. To break it down:\n",
        "- $v$ is the membrane potential of the neuron.\n",
        "- $(-v + v_r) / \\tau_m$ : This term describes how the membrane potential decays to the reset potential $v_r$ over time, governed by the membrane time constant $\\tau_m$, a.k.a. the leaky integrator.\n",
        "- $(I + I_{ext}) / C_m$ : This term adds the effects of input currents: $I$ is the synaptic current received by the neuron. $I_{ext}$ is an external current applied to the neuron.\n",
        "\n",
        "You can read more about the derivation of this equation [here](https://neuronaldynamics.epfl.ch/online/Ch1.S3.html).\n",
        "\n",
        "Now we need to transform this equation into something interpretable to Python. Thanks to brian2, this process is very much simplified. We first assign values to several LIF parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ-m83gf-wl3"
      },
      "outputs": [],
      "source": [
        "def LIFparams():\n",
        "    tau_m = 10.0 * ms  # membrane time constant\n",
        "    tau_ref = 2.0 * ms  # absolute refractory period\n",
        "    Cm = 250.0 * pF  # membrane capacity\n",
        "    v_r = -65.0 * mV  # reset potential\n",
        "    v_th = -50.0 * mV  # fixed firing threshold\n",
        "    return tau_m, tau_ref, Cm, v_r, v_th\n",
        "\n",
        "# Note. Using brian2, you can add SI units to the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boKOGSVeEYWx"
      },
      "source": [
        "Now let's try write down the linear differential equation we've just seen with brian2. Note that you need to add the unit of the variable defined by the equation (in this case, volt) after a colon. And also in this particular case, you need to append `(unless refractory)` to the end of the equation. You may read more about brian2 usage in general [here](https://brian2.readthedocs.io/en/stable/resources/tutorials/1-intro-to-brian-neurons.html).\n",
        "\n",
        "<font color=\"green\">**To Do 1-1**</font> Replace `###YOUR CODE###` with the equation. Remember to remove `raise NotImplementedError` after you inserted your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np9hA3SZEPqf"
      },
      "outputs": [],
      "source": [
        "# Leaky integrate-and-fire model equations\n",
        "# I: synaptic current\n",
        "# tau_syn: synaptic time constant\n",
        "# Iext: external current\n",
        "LIFmodel = '''\n",
        "\t###YOUR CODE###\n",
        "\tdI/dt = -I/tau_syn : amp\n",
        "\tIext : amp\n",
        "\t'''\n",
        "# Reset condition\n",
        "resetLIF = '''\n",
        "\tv = v_r\n",
        "\t'''\n",
        "\n",
        "raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yJhdETqIFLJH"
      },
      "outputs": [],
      "source": [
        "#@title Solution To Do 1-1\n",
        "\n",
        "# Leaky integrate-and-fire model equations\n",
        "# I: synaptic current\n",
        "# tau_syn: synaptic time constant\n",
        "# Iext: external current\n",
        "LIFmodel = '''\n",
        "\tdv/dt = (-v + v_r)/tau_m + (I+Iext)/Cm : volt (unless refractory)\n",
        "\tdI/dt = -I/tau_syn : amp\n",
        "\tIext : amp\n",
        "\t'''\n",
        "# Reset condition\n",
        "resetLIF = '''\n",
        "\tv = v_r\n",
        "\t'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF9b5T9-S03w"
      },
      "source": [
        "So far we have defined the core passive membrane behavior pattern of a LIF neuron, and also how it handles external inputs. The firing threshold and refractory period length are fixed in our equation. That's basically evertything we need for a single LIF neuron. We just need to set up some initial parameter values when we actually run it.\n",
        "\n",
        "Now let's proceed to connecting those neurons.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss0CJlIGkw7l"
      },
      "source": [
        "### Balanced Random Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBnH0yZdnhGk"
      },
      "source": [
        "The balanced random network model is what we are using to characterize the neuronal population dynamics. It receives external inputs (i.e., background inputs) and propagate the stimulation to the whole network through synapses. Previous studies provided valuable data of the population size and the connection probabilities, and we can build the network based on it. Let's take a look and run the network parameters.\n",
        "\n",
        "\n",
        "> Connection probability: the probability that a neuron in the presynaptic population forms at least 1 synapse with a neuron in the postsynaptic population.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Network parameters\n",
        "###############################################################################\n",
        "# Population size per layer\n",
        "#          2/3e   2/3i   4e    4i    5e    5i    6e     6i    Th\n",
        "n_layer = [20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948, 902]\n",
        "\n",
        "# Total cortical Population\n",
        "N = sum(n_layer[:-1])\n",
        "\n",
        "# Number of neurons accumulated\n",
        "nn_cum = [0]\n",
        "nn_cum.extend(cumsum(n_layer))\n",
        "\n",
        "# Prob. connection table\n",
        "#          From 2/3e    2/3i   4e     4i     5e     5i      6e     6i      Th        To\n",
        "table = array([[0.101,  0.169, 0.044, 0.082, 0.032, 0.,     0.008, 0.,     0.    ], #2/3e\n",
        "               [0.135,  0.137, 0.032, 0.052, 0.075, 0.,     0.004, 0.,     0.    ], #2/3i\n",
        "               [0.008,  0.006, 0.050, 0.135, 0.007, 0.0003, 0.045, 0.,     0.0983], #4e\n",
        "               [0.069,  0.003, 0.079, 0.160, 0.003, 0.,     0.106, 0.,     0.0619], #4i\n",
        "               [0.100,  0.062, 0.051, 0.006, 0.083, 0.373,  0.020, 0.,     0.    ], #5e\n",
        "               [0.055,  0.027, 0.026, 0.002, 0.060, 0.316,  0.009, 0.,     0.    ], #5i\n",
        "               [0.016,  0.007, 0.021, 0.017, 0.057, 0.020,  0.040, 0.225,  0.0512], #6e\n",
        "               [0.036,  0.001, 0.003, 0.001, 0.028, 0.008,  0.066, 0.144,  0.0196]])#6i\n",
        "\n",
        "# Synapses parameters\n",
        "d_ex = 1.5*ms      \t# Excitatory delay\n",
        "std_d_ex = 0.75*ms \t# Std. Excitatory delay\n",
        "d_in = 0.80*ms      # Inhibitory delay\n",
        "std_d_in = 0.4*ms  \t# Std. Inhibitory delay\n",
        "tau_syn = 0.5*ms    # Post-synaptic current time constant\n",
        "\n",
        "# Layer-specific background input\n",
        "bg_layer_specific = array([1600, 1500 ,2100, 1900, 2000, 1900, 2900, 2100])\n",
        "\n",
        "# Layer-independent background input\n",
        "bg_layer_independent = array([2000, 1850 ,2000, 1850, 2000, 1850, 2000, 1850])"
      ],
      "metadata": {
        "id": "Il94u9FJFT0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asl4Y-4Xu8On"
      },
      "source": [
        "We can see that the population size per layer, the connection probabilities, and the synapse parameters are already filled out. The connection table shows there might be recurrent intralayer connections (e.g., L2/3e -> L2/3e) and interlayer connections (e.g., L2/3e -> L4e). Note that every column shows the connections *from* the same presynaptic neurons, and every row shows the connection *to* the same postsynaptic neurons (the thalamic neurons can only serve as presynaptic neurons!).\n",
        "\n",
        "You may also notice that there are layer-specific background inputs, which are external inputs to each layer and the numbers are estimated through experimental research. There are also layer-independent inputs, which have the identical number for every layer. The layer-independent inputs are used to test the robustness of this network. Actually, you may define the input array in various way to simulate different external input patterns. We'll talk about it later on in the robustness tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVrtkYNeri9e"
      },
      "source": [
        "<font color=\"red\">**To Think 1-2**</font>: The population size per layer is determined by anatomical studies. What is the approximate proportion of exitatory cells to inhibitory cells? What do you predict to happen in the network if we assign the same weight to synapses to inhibitory cells and synapses to excitatory cells?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35dQVSiJtGEb"
      },
      "source": [
        "With the population sizes, connection probabilities, and the synaptic data, we can wire up the neurons. In a balanced random network, every neuronal population forms connections to every other population, and the exact number of synapses in the connections is determined by the connection probability and population size. Once has the synapse quantity settled, the synapases are randomly distributed to the neurons in the population.\n",
        "\n",
        "Now we have the population sizes and the connection probabilities, then we can calculate the number of synapses by the following equation:\n",
        "\n",
        "$$\n",
        "C_a = 1 - (1 - \\frac{1}{N^{pre}N^{post}})^K\n",
        "$$\n",
        "\n",
        "$C_a$ is the connection probability, $N^{pre}$ and $N^{post}$ denote the presynaptic and postsynaptic neuron numbers, and $K$ is the number of the synapses.\n",
        "\n",
        "With a bit transformation, we obtain:\n",
        "\n",
        "$$\n",
        "K = \\ln(C_a) / \\ln(1 - (1 - \\frac{1}{N^{pre}N^{post}}))\n",
        "$$\n",
        "\n",
        "We can also consider using the Taylor series approximation of the original equation:\n",
        "\n",
        "$$\n",
        "C_a = \\frac{K}{N^{pre}N^{post}} â‡’ K = \\frac{C_a}{N^{pre} N^{post}}\n",
        "$$\n",
        "\n",
        "Much simpler! Later, we can test those two different ways to calculating synapse numbers and see if it affects the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KeNROimMepU"
      },
      "source": [
        "<font color=\"red\">**To Think 1-3**</font>: Try to derive the connection probability equation (Hint: think about the definition of connection probability)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obE8mdlqMzTV"
      },
      "source": [
        "\n",
        "Solution To Think 1-3\n",
        "\n",
        "<details>\n",
        "  <summary>Click to expand</summary>\n",
        "We know that the connection probability is \"the probability that a neuron in the presynaptic population forms at least 1 synapse with a neuron in the postsynaptic population\". In other words, it is one minus the probability that a neuron in the presynaptic population forms no synapse to a neuron in the postsynaptic population.\n",
        "\n",
        "$$C_a = 1 - P(\\text{no synapse})$$\n",
        "\n",
        "There are $N^{pre}N^{post}$ forms of synapses connecting different neurons. Imagine we are distributing K synapses to those niches, the probability of a particular synapse connecting two particular neurons will be $$\\frac{1}{N^{pre}N^{post}}$$\n",
        "\n",
        "And the opposite of that is this particular synapse does not connect those two neurons. The probability of this happening is $$1 - \\frac{1}{N^{pre}N^{post}}$$\n",
        "\n",
        "Then, the probability of none of the $K$ synapses connecting those two neurons, namely the probability that a neuron in the presynaptic population forms no synapse to a neuron in the postsynaptic population, would be $$(1 - \\frac{1}{N^{pre}N^{post}})^K$$ We can substitute $P(\\text{no synapse})$ with this, and finally we have\n",
        "\n",
        "$$C_a = 1 - (1 - \\frac{1}{N^{pre}N^{post}})^K$$\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPhB15L_jEg2"
      },
      "source": [
        "Once we have number of the synapses between two populations, we can randomly assign the synapses to the neurons. It's time for some Python coding!\n",
        "\n",
        "<font color=\"green\">**To Do 1-2**</font>: Replace `###YOUR CODE###` with the connection probability-synapse number equation(s). We use variable `nsyn` to denote the number of the synapses. Be aware: the number of synapses must be integers.\n",
        "\n",
        "Remember to remove `raise NotImplementedError` after you inserted your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlNnMR1_jZvY"
      },
      "outputs": [],
      "source": [
        "def PDnet(NeuronGroup, stim, bg_type, w_ex, g, bg_freq, nsyn_type, thal):\n",
        "    # P and D are the initials of the authors of the paper\n",
        "\n",
        "    w_ex = w_ex*pA\t\t   \t# excitatory synaptic weight\n",
        "    std_w_ex = 0.1*w_ex     # standard deviation weight\n",
        "\n",
        "    pop = [] # Stores NeuronGroups, one for each population\n",
        "    for r in range(0, 8):\n",
        "        pop.append(NeuronGroup[nn_cum[r]:nn_cum[r+1]])\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating synapse connections\n",
        "    ###########################################################################\n",
        "\n",
        "    syn_model = '''\n",
        "                w:amp\t\t\t# synaptic weight\n",
        "                '''\n",
        "\n",
        "    # equations executed only when presynaptic spike occurs:\n",
        "    # for excitatory connections\n",
        "    pre_eq = '''\n",
        "            I_post += w\n",
        "            '''\n",
        "\n",
        "    con = [] # Stores connections\n",
        "\n",
        "    ###########################################################################\n",
        "    # Connecting neurons\n",
        "    ###########################################################################\n",
        "    pre_index = [] # presynaptic neuron index\n",
        "    post_index = [] # postsynaptic neuron index\n",
        "\n",
        "    # c: column (presynaptic neurons)\n",
        "    # r: row (postsynaptic neurons)\n",
        "    for c in range(0, 8):\n",
        "        for r in range(0, 8):\n",
        "\n",
        "            if (nsyn_type==0):\n",
        "                # number of synapses calculated with the original equation\n",
        "                ###YOUR CODE###\n",
        "                raise NotImplementedError\n",
        "            elif (nsyn_type==1):\n",
        "                # number of synapses calculated with the Taylor series approximation\n",
        "                ###YOUR CODE###\n",
        "                raise NotImplementedError\n",
        "            pre_index = randint(n_layer[c], size=nsyn)\n",
        "            post_index = randint(n_layer[r], size=nsyn)\n",
        "\n",
        "            # Assign weights to the synapses\n",
        "            if nsyn<1:\n",
        "                pass\n",
        "            else:\n",
        "                # Excitatory connections\n",
        "                if (c % 2) == 0:\n",
        "                    # Synaptic weight from L4e to L2/3e is doubled as the data basis for these connections is not fully conclusive\n",
        "                    if c == 2 and r == 0:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = '2.0*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    else:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = 'clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_ex + std_d_ex*randn(), 0.1*ms, d_ex*inf)'\n",
        "\n",
        "                # Inhibitory connections\n",
        "                else:\n",
        "                    con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                    con[-1].connect(i = pre_index, j = post_index)\n",
        "                    con[-1].w = '-g*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_in + std_d_in*randn(), 0.1*ms, d_in*inf)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_oa1vE4UoVJ8"
      },
      "outputs": [],
      "source": [
        "#@title Solution To Do 1-2\n",
        "def PDnet(NeuronGroup, stim, bg_type, w_ex, g, bg_freq, nsyn_type, thal):\n",
        "\n",
        "    w_ex = w_ex*pA\t\t   \t# excitatory synaptic weight\n",
        "    std_w_ex = 0.1*w_ex     # standard deviation weight\n",
        "\n",
        "    pop = [] # Stores NeuronGroups, one for each population\n",
        "    for r in range(0, 8):\n",
        "        pop.append(NeuronGroup[nn_cum[r]:nn_cum[r+1]])\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating synapse connections\n",
        "    ###########################################################################\n",
        "\n",
        "    syn_model = '''\n",
        "                w:amp\t\t\t# synaptic weight\n",
        "                '''\n",
        "\n",
        "    # equations executed only when presynaptic spike occurs:\n",
        "    # for excitatory connections\n",
        "    pre_eq = '''\n",
        "            I_post += w\n",
        "            '''\n",
        "\n",
        "    con = [] # Stores connections\n",
        "\n",
        "    ###########################################################################\n",
        "    # Connecting neurons\n",
        "    ###########################################################################\n",
        "    pre_index = [] # presynaptic neuron index\n",
        "    post_index = [] # postsynaptic neuron index\n",
        "\n",
        "    # c: column (presynaptic neurons)\n",
        "    # r: row (postsynaptic neurons)\n",
        "    for c in range(0, 8):\n",
        "        for r in range(0, 8):\n",
        "\n",
        "            if (nsyn_type==0):\n",
        "                # number of synapses calculated with the original equation\n",
        "                nsyn = int(log(1.0-table[r][c])/log(1.0 - (1.0/float(n_layer[c]*n_layer[r]))))\n",
        "            elif (nsyn_type==1):\n",
        "                # number of synapses calculated with the Taylor series approximation\n",
        "                nsyn = int(n_layer[c]*n_layer[r]*table[r][c])\n",
        "            pre_index = randint(n_layer[c], size=nsyn)\n",
        "            post_index = randint(n_layer[r], size=nsyn)\n",
        "\n",
        "            # assign weights to the synapses\n",
        "            if nsyn<1:\n",
        "                pass\n",
        "            else:\n",
        "                # Excitatory connections\n",
        "                if (c % 2) == 0:\n",
        "                    # Synaptic weight from L4e to L2/3e is doubled\n",
        "                    if c == 2 and r == 0:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = '2.0*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    else:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = 'clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_ex + std_d_ex*randn(), 0.1*ms, d_ex*inf)'\n",
        "\n",
        "                # Inhibitory connections\n",
        "                else:\n",
        "                    con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                    con[-1].connect(i = pre_index, j = post_index)\n",
        "                    con[-1].w = '-g*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_in + std_d_in*randn(), 0.1*ms, d_in*inf)'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnjiTL7QygsT"
      },
      "source": [
        "<font color=\"red\">**To Think 1-4**</font>: You may noticed that every synapse has been assigned with a weight. The assignments to excitatory connections and inhibitory connections are a bit different:\n",
        "```\n",
        "#Excitatory connections\n",
        "...\n",
        "con[-1].w = 'clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "...\n",
        "# Inhibitory connections\n",
        "con[-1].w = '-g*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "```\n",
        "\n",
        "The variable `g` is called inhibitory weight balance, and its default value in this tutorial is 4. Does the value remind you of something about the neuronal population size? Why do we balance the inhibitory weight?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6acceLh1QNu"
      },
      "source": [
        "The connections within the network are created, and there's one more thing we need to do: handling external inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnoWbrf84xFM"
      },
      "source": [
        "```\n",
        "    ###########################################################################\n",
        "    # Setting background input values\n",
        "    ###########################################################################\n",
        "    \n",
        "    # Background number per layer\n",
        "    if bg_type == 0:\n",
        "        # layer-specific:\n",
        "        bg_layer = bg_layer_specific\n",
        "    elif bg_type == 1:\n",
        "        # layer-independent:\n",
        "        bg_layer = bg_layer_independent\n",
        "```\n",
        "We have defined two types of background inputs\n",
        "1. layer-specific: external inputs from grey matter, white matter, and thalamic (independent from the thalamic inputs we defined in the parameters) sources. The number is determined by empirical research.\n",
        "2. layer-independent: also external inputs from grey and white matter. The number is set as identical for each layer.\n",
        "\n",
        "You can look up the network parameters for the layer-specific and layer-independent numbers.\n",
        "\n",
        "The reason for layer-independent is that the data basis for layer-specific inputs is actually limited. To rigorously test this network, we need to investigate other input parameterization's effects. We can also create other custom background types to do more testing.\n",
        "\n",
        "```\n",
        "    ###########################################################################\n",
        "    # Creating poissonian and DC-current background inputs\n",
        "    ###########################################################################\n",
        "    bg_in  = []\n",
        "    if (stim==0):\n",
        "        for r in range(0, 8):\n",
        "            bg_in.append(PoissonInput(pop[r], 'I', bg_layer[r], bg_freq*Hz, weight=w_ex))\n",
        "    \n",
        "    # DC-current normalized by population\n",
        "    if (stim == 1):\n",
        "        for r in range(0, 8):\n",
        "            NeuronGroup.Iext[pop[r]] = 0.3512*pA*bg_layer[r]\n",
        "```\n",
        "We also model two types inputs: poissonian and DC-current background inputs:\n",
        "\n",
        "> Poissonian input: a type of stochastic or random input where the timing of incoming spikes follows a poisson process. This means the spikes arrive randomly but with a certain average rate. Poissonian input is used to simulate background synaptic noise.\n",
        "\n",
        "> DC (direct current) input: a constant or fixed input current applied to the neuron. Unlike Poissonian input, it does not vary over time. This input is analogous to injecting a constant electrical current into a neuron. DC input is often used to simulate a constant external stimulus.\n",
        "\n",
        "We can test these two types of inputs in the later robustness tests.\n",
        "\n",
        "```\n",
        "    ###############################################################################\n",
        "    # Creating thalamic neurons as poissonian inputs\n",
        "    ###############################################################################\n",
        "    thal_con = []\n",
        "    thal_input = []\n",
        "    if thal==\"ON\":\n",
        "        thal_input = PoissonGroup(n_layer[8], rates=120.0*Hz)\t#from PD paper: rates=15Hz\n",
        "        for r in range(0,8):\n",
        "            thal_con.append(Synapses(thal_input, pop[r], model=syn_model, on_pre=pre_eq))\n",
        "            thal_con[-1].connect(p=table[r][8])\n",
        "            thal_con[-1].w = 0.0\n",
        "```\n",
        "\n",
        "To simulate stimulus-evoked activity, we explicitly model the thalamic input to L4 and L6 by a thalamic population of 902 neurons (Peters and Payne 1993). You can find its own neuronal population and connection probabilities in the network parameters section. By defining the thalamic input this way, we can fine-tune the thalamic inputs towards specific neuronal populations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VwxM3mHr96H"
      },
      "source": [
        "Phew, we finally have everything for the network building! Now we just need to assemble the modules to create the complete network function. We also need to add a spike monitor to the network to collect the spiking data.\n",
        "\n",
        "<font color=\"green\">**To Do 1-3**</font> (1) Copy and paste the modules to assemble the `PDNet` (2) Create a spike monitor called `smon_net` using brian2 at the end of the function. You can refer to the [brian2 tutorial](https://brian2.readthedocs.io/en/stable/resources/tutorials/1-intro-to-brian-neurons.html) about how to do it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GygdWm5ptXPj"
      },
      "outputs": [],
      "source": [
        "def PDnet(NeuronGroup, stim, bg_type, w_ex, g, bg_freq, nsyn_type, thal):\n",
        "    # P and D are the initials of the authors of the paper\n",
        "\n",
        "    w_ex = w_ex*pA\t\t   \t# excitatory synaptic weight\n",
        "    std_w_ex = 0.1*w_ex     # standard deviation weight\n",
        "\n",
        "    pop = [] # Stores NeuronGroups, one for each population\n",
        "    for r in range(0, 8):\n",
        "        pop.append(NeuronGroup[nn_cum[r]:nn_cum[r+1]])\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating synapse connections\n",
        "    ###########################################################################\n",
        "\n",
        "    syn_model = '''\n",
        "                w:amp\t\t\t# synaptic weight\n",
        "                '''\n",
        "\n",
        "    # equations executed only when presynaptic spike occurs:\n",
        "    # for excitatory connections\n",
        "    pre_eq = '''\n",
        "            I_post += w\n",
        "            '''\n",
        "\n",
        "    con = [] # Stores connections\n",
        "\n",
        "    ###########################################################################\n",
        "    # Connecting neurons\n",
        "    ###########################################################################\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "    ###########################################################################\n",
        "    # Setting background input values\n",
        "    ###########################################################################\n",
        "\n",
        "    # Background number per layer\n",
        "    if bg_type == 0:\n",
        "        # layer-specific:\n",
        "        bg_layer = bg_layer_specific\n",
        "    elif bg_type == 1:\n",
        "        # layer-independent:\n",
        "        bg_layer = bg_layer_independent\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating poissonian and DC-current background inputs\n",
        "    ###########################################################################\n",
        "    bg_in  = []\n",
        "    # poissonian inputs\n",
        "    if (stim==0):\n",
        "        for r in range(0, 8):\n",
        "            bg_in.append(PoissonInput(pop[r], 'I', bg_layer[r], bg_freq*Hz, weight=w_ex))\n",
        "\n",
        "    # DC-current normalized by population\n",
        "    if (stim == 1):\n",
        "        for r in range(0, 8):\n",
        "            NeuronGroup.Iext[pop[r]] = 0.3512*pA*bg_layer[r]\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating thalamic neurons as poissonian inputs\n",
        "    ###########################################################################\n",
        "    thal_con = []\n",
        "    thal_input = []\n",
        "    if thal==\"ON\":\n",
        "        thal_input = PoissonGroup(n_layer[8], rates=120.0*Hz)    #from PD paper: rates=15Hz\n",
        "        for r in range(0,8):\n",
        "            thal_con.append(Synapses(thal_input, pop[r], model=syn_model, on_pre=pre_eq))\n",
        "            thal_con[-1].connect(p=table[r][8])\n",
        "            thal_con[-1].w = 0.0\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating spike monitors\n",
        "    ###########################################################################\n",
        "    ##YOUR CODE##\n",
        "    raise NotImplementedError\n",
        "\n",
        "    return pop, con, bg_in, smon_net, thal_input ,thal_con"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6ShS0wazsVc"
      },
      "outputs": [],
      "source": [
        "#@title Solution To Do 1-3\n",
        "\n",
        "def PDnet(NeuronGroup, stim, bg_type, w_ex, g, bg_freq, nsyn_type, thal):\n",
        "    # P and D are the initials of the authors of the paper\n",
        "\n",
        "    w_ex = w_ex*pA\t\t   \t# excitatory synaptic weight\n",
        "    std_w_ex = 0.1*w_ex     # standard deviation weight\n",
        "\n",
        "    pop = [] # Stores NeuronGroups, one for each population\n",
        "    for r in range(0, 8):\n",
        "        pop.append(NeuronGroup[nn_cum[r]:nn_cum[r+1]])\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating synapse connections\n",
        "    ###########################################################################\n",
        "\n",
        "    syn_model = '''\n",
        "                w:amp\t\t\t# synaptic weight\n",
        "                '''\n",
        "\n",
        "    # equations executed only when presynaptic spike occurs:\n",
        "    # for excitatory connections\n",
        "    pre_eq = '''\n",
        "            I_post += w\n",
        "            '''\n",
        "\n",
        "    con = [] # Stores connections\n",
        "\n",
        "    ###########################################################################\n",
        "    # Connecting neurons\n",
        "    ###########################################################################\n",
        "\n",
        "    pre_index = [] # presynaptic neuron index\n",
        "    post_index = [] # postsynaptic neuron index\n",
        "\n",
        "    # c: column (presynaptic neurons)\n",
        "    # r: row (postsynaptic neurons)\n",
        "    for c in range(0, 8):\n",
        "        for r in range(0, 8):\n",
        "\n",
        "            if (nsyn_type==0):\n",
        "                # number of synapses calculated with the original equation\n",
        "                nsyn = int(log(1.0-table[r][c])/log(1.0 - (1.0/float(n_layer[c]*n_layer[r]))))\n",
        "            elif (nsyn_type==1):\n",
        "                # number of synapses calculated with the Taylor series approximation\n",
        "                nsyn = int(n_layer[c]*n_layer[r]*table[r][c])\n",
        "            pre_index = randint(n_layer[c], size=nsyn)\n",
        "            post_index = randint(n_layer[r], size=nsyn)\n",
        "\n",
        "            # assign weights to the synapses\n",
        "            if nsyn<1:\n",
        "                pass\n",
        "            else:\n",
        "                # Excitatory connections\n",
        "                if (c % 2) == 0:\n",
        "                    # Synaptic weight from L4e to L2/3e is doubled\n",
        "                    if c == 2 and r == 0:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = '2.0*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    else:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = 'clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_ex + std_d_ex*randn(), 0.1*ms, d_ex*inf)'\n",
        "\n",
        "                # Inhibitory connections\n",
        "                else:\n",
        "                    con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                    con[-1].connect(i = pre_index, j = post_index)\n",
        "                    con[-1].w = '-g*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_in + std_d_in*randn(), 0.1*ms, d_in*inf)'\n",
        "\n",
        "    ###########################################################################\n",
        "    # Setting background input values\n",
        "    ###########################################################################\n",
        "\n",
        "    # Background number per layer\n",
        "    if bg_type == 0:\n",
        "        # layer-specific:\n",
        "        bg_layer = bg_layer_specific\n",
        "    elif bg_type == 1:\n",
        "        # layer-independent:\n",
        "        bg_layer = bg_layer_independent\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating poissonian and DC-current background inputs\n",
        "    ###########################################################################\n",
        "    bg_in  = []\n",
        "    if (stim==0):\n",
        "        for r in range(0, 8):\n",
        "            bg_in.append(PoissonInput(pop[r], 'I', bg_layer[r], bg_freq*Hz, weight=w_ex))\n",
        "\n",
        "    # DC-current normalized by population\n",
        "    if (stim == 1):\n",
        "        for r in range(0, 8):\n",
        "            NeuronGroup.Iext[pop[r]] = 0.3512*pA*bg_layer[r]\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating thalamic neurons as poissonian inputs\n",
        "    ##########################################################################\n",
        "    thal_con = []\n",
        "    thal_input = []\n",
        "    if thal==\"ON\":\n",
        "        thal_input = PoissonGroup(n_layer[8], rates=120.0*Hz) #from PD paper: rates=15Hz\n",
        "        for r in range(0,8):\n",
        "            thal_con.append(Synapses(thal_input, pop[r], model=syn_model, on_pre=pre_eq))\n",
        "            thal_con[-1].connect(p=table[r][8])\n",
        "            thal_con[-1].w = 0.0\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating spike monitors\n",
        "    ###########################################################################\n",
        "    smon_net = SpikeMonitor(NeuronGroup)\n",
        "\n",
        "    return pop, con, bg_in, smon_net, thal_input ,thal_con"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgEDdRZz2S4B"
      },
      "source": [
        "For the simulation, we still need to create a `runParams` function, so we can decide how long the simulation persists, the background input type, whether turn on the thalamic inputs, etc. And we also need use this function to add the LIF model definition to the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8U2uFnS2Sfq"
      },
      "outputs": [],
      "source": [
        "def runParams(tsim=1.0, bg_type=0, stim=0, w_ex=87.8, g=4.0, bg_freq=8.0, nsyn_type=0, thal='OFF', filename=None):\n",
        "\n",
        "    ###########################################################################\n",
        "    # Simulation parameters\n",
        "    ###########################################################################\n",
        "    defaultclock.dt = 0.1*ms    # timestep of numerical integration method\n",
        "\n",
        "    # neuron model\n",
        "    eqs = LIFmodel\n",
        "    reset = resetLIF\n",
        "    tau_m, tau_ref, Cm, v_r, v_th = LIFparams()\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating neurons\n",
        "    ###########################################################################\n",
        "    neurons = NeuronGroup(N, eqs, threshold='v>v_th', reset=reset, \\\n",
        "                            method='linear', refractory=tau_ref)\n",
        "\n",
        "    # seting initial values for membrane potential and currents\n",
        "    neurons.v = '-58.0*mV + 10.0*mV*randn()'\n",
        "    neurons.I = 0.0*pA      # initial value for synaptic currents\n",
        "    neurons.Iext = 0.0*pA   # constant external current\n",
        "\n",
        "    pop, con, bg_in, smon_net, thal_input, thal_con = PDnet(neurons, stim, \\\n",
        "                                            bg_type, w_ex, g, bg_freq, nsyn_type, thal)\n",
        "\n",
        "    ###########################################################################\n",
        "    # Running the simulation\n",
        "    ###########################################################################\n",
        "    net = Network(collect())\n",
        "\n",
        "    if (thal == 'OFF'):\n",
        "        net.add(neurons,pop, con, bg_in)    # Adding objects to the simulation\n",
        "        net.run(tsim*second, report='stdout')\n",
        "\n",
        "    elif (thal == 'ON'):\n",
        "        w_thal = w_ex*pA            # excitatory synaptic weight from thalamus\n",
        "        std_w_thal = w_thal*0.1     # standard deviation weigth\n",
        "        net.add(neurons,pop, con, bg_in, thal_input, thal_con)    # Adding objects to the simulation\n",
        "\n",
        "        for repeat in range(0,int(tsim)):\n",
        "            net.run(0.7*second,report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "            # Adding thalamic input\n",
        "            for r in range(0,8):\n",
        "                thal_con[r].w = 'clip((w_thal + std_w_thal*randn()),w_thal*0.0, w_thal*inf)'\n",
        "            net.run(0.01*second, report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "            # Removing thalamic input\n",
        "            for r in range(0,8):\n",
        "                thal_con[r].w = 0\n",
        "            net.run(0.29*second, report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "    ###########################################################################\n",
        "    # Saving raster plot\n",
        "    ###########################################################################\n",
        "    savetxt(filename, c_[smon_net.i,smon_net.t/ms],fmt=\"%i %.2f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAvmaobAyPDO"
      },
      "source": [
        "## 2. Spontaneous Activity\n",
        "### Simulation\n",
        "\n",
        "Now we may begin the network simulation. We start with the spontaneous activity where there is only background Poissonian inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NM0th_O24kzL"
      },
      "outputs": [],
      "source": [
        "#@title Helper Functions: Simulation General\n",
        "def filename(g, bgrate, suffix = ''):\n",
        "    return '../data/data_raster_g' + str(g) + '_bgrate' + str(bgrate) +  suffix + '.dat'\n",
        "\n",
        "# Function used in multiple runs: define different random seeds and clean memory\n",
        "def runParamsParallel(s=1, g=4, bg_type=0, bg_freq=8.0, stim=0, tsim=1.0, filename=None):\n",
        "    seed(s*1000)\n",
        "    runParams(tsim=tsim, bg_type=bg_type, stim=stim, g=g, bg_freq=bg_freq, filename=filename)\n",
        "    gc.collect()\n",
        "\n",
        "# default seed of pseudo random numbers to test reproducibility\n",
        "s = 1000\n",
        "seed(s)\n",
        "\n",
        "# choose serial = False to run multiple simulations in parallel\n",
        "serial = True\n",
        "num_cores = -1 # number of cores to run in parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*. All the result data is stored in `/content/drive/MyDrive/spike_network/data`. And they are named using `g`, `bg`, and a custom suffix. Check the helper functions for naming rules."
      ],
      "metadata": {
        "id": "P2N3xHcyRDFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s43xXIow4rBR"
      },
      "outputs": [],
      "source": [
        "# run the spontaneous activity simulation\n",
        "\n",
        "# it is recommended to simulate the network for 60 secs or longer, but since our\n",
        "# class time is limited, we'll only simulate 1 sec, which may take ~2 min\n",
        "\n",
        "# the initialization of the network may be slow due to unknown reasons,\n",
        "# which may prolong the execution to ~10 min or even more. If you think it's\n",
        "# going too slow, you can try run the next code cell as an alternative option\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 0 # Poissonian inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, filename=filename(g, bg, 'default'))\n",
        "gc.collect() #garbage collector to clean memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jqm28W3A3a-t",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Alternative Simulation Option\n",
        "\n",
        "# run the simulation!\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "# Note. It may take time longer than expected due to variance in initialization\n",
        "!python netRun.py 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJkJ3HQIOz1-"
      },
      "source": [
        "### Raster Plot\n",
        "\n",
        "We can make a raster plot to showcase the spiking of neurons in the simulation time. Before plotting, the spiking data needs to be sampled and sorted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peZzUeq0nm1e"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Defining plotting parameters\n",
        "###############################################################################\n",
        "\n",
        "# cortical layer labels: e for excitatory; i for inhibitory\n",
        "lname = ['L23e', 'L23i', 'L4e', 'L4i', 'L5e', 'L5i','L6e', 'L6i']\n",
        "\n",
        "# number of neurons by layer\n",
        "n_layer_plot = [0, 20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948];\n",
        "l_bins = np.cumsum(n_layer_plot) # cumulative number of neurons by layer\n",
        "N = np.sum(n_layer_plot)         # total number of neurons\n",
        "\n",
        "# sampling parameters\n",
        "psample = 0.025 # percentage of neurons by layer for the raster plot\n",
        "n_sample = 1000 # number of neurons by layer for sampled measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_DRsT90nAro"
      },
      "outputs": [],
      "source": [
        "def preprocess(tsim, filename, lname, n_layer_plot, l_bins, N, psample, n_sample):\n",
        "  #############################################################################\n",
        "  # Loading data and defining parameters\n",
        "  #############################################################################\n",
        "  data = pd.read_csv(filename, sep=\" \",\n",
        "                      header=None, names=['i','t'])\n",
        "\n",
        "  # grouping spiking times for each neuron\n",
        "  keys,values = data.sort_values(['i','t']).values.T\n",
        "  ukeys,index=np.unique(keys,True)\n",
        "  arrays=np.split(values,index[1:])\n",
        "\n",
        "  spk_neuron = pd.DataFrame({'i':range(0,N),'t':[[]]*N})\n",
        "\n",
        "  # DEPRECATED: List of arrays cannot be directly assigned to dataframe\n",
        "  # spk_neuron.iloc[ukeys.astype(int),1] = arrays\n",
        "  for neuron_index, spike_times in zip(ukeys.astype(int), arrays):\n",
        "      spk_neuron.at[neuron_index, 't'] = spike_times.tolist()\n",
        "\n",
        "  # creating a flag to identify cortical layers\n",
        "  spk_neuron['layer'] = pd.cut(spk_neuron['i'], l_bins, labels=lname, right=False)\n",
        "  data['layer'] = pd.cut(data['i'], l_bins, labels=lname, right=False)\n",
        "\n",
        "  # sampling data:\n",
        "  spk_neuron = spk_neuron.groupby(['layer'], observed=False).apply(lambda x: x.sample(n=n_sample))\n",
        "\n",
        "  # reset the index to remove the ambiguity\n",
        "  spk_neuron = spk_neuron.reset_index(drop=True)\n",
        "\n",
        "  # measures DataFrame to store firing rates, synchrony, and irrgularity\n",
        "  measures_layer = pd.DataFrame(index=lname)\n",
        "\n",
        "  return spk_neuron, measures_layer, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFfOyIuAoVV-"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "spk_neuron, measures_layer, data = preprocess(tsim, filename(g, bg, 'default'), lname, n_layer_plot, l_bins, N, psample, n_sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def rasterplot(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample):\n",
        "  ###############################################################################\n",
        "  # Raster plot\n",
        "  ###############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "  plt.gca().set_yticklabels([])\n",
        "  acum_index = 0\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "      index_start = l_bins[i]\n",
        "      index_end = l_bins[i]+int(psample*n_layer_plot[i+1])\n",
        "\n",
        "      x = data.t[data.i.isin(range(index_start,index_end))]\n",
        "      y = data.i[data.i.isin(range(index_start,index_end))] + acum_index - index_start\n",
        "\n",
        "      plt.plot(x/1000.0,y,'.',markersize=dotsize,color=dotcolor[i])\n",
        "\n",
        "      # layers labels\n",
        "      xpos = tsim-440/1000.0\n",
        "      ypos = acum_index + (index_end-index_start)/2.0\n",
        "      plt.text(xpos,ypos,lname[i],horizontalalignment='center', fontweight='bold')\n",
        "\n",
        "      acum_index = acum_index + (index_end-index_start)\n",
        "\n",
        "  plt.xlim(tsim-400/1000.0,tsim)\n",
        "  plt.ylim(0,acum_index)\n",
        "  plt.xlabel('time [s]')\n",
        "  plt.ylabel(' ')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "9d10FX7op0Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rasterplot(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)"
      ],
      "metadata": {
        "id": "JvA7fASVsgiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puKNeNRHrJES"
      },
      "source": [
        "In this raster plot, we display the spiking per layer of 0.025 of the total neurons in the last 400 ms in our simulation.\n",
        "\n",
        "<font color=\"red\">**To Think 2-1**</font> What can you tell from this raster plot demonstrating the spontaneous activities of this networks? Does it align with [the figure in the original paper](https://academic.oup.com/view-large/figure/80937186/bhs35806.gif)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkxuHwypsUpP"
      },
      "source": [
        "The raster plot exhibits the different spiking behaviours across those layers. Other quantative measures are also quite informative. We will plot the firing rate, irrgularity, and synchrony of each neuron population.\n",
        "> **Firing Rate**: the number of spikes a neuron generates per unit of time\n",
        "\n",
        "> **Irregularity**: single-unit spike trains quantified by the coefficient of variation of the interspike intervals.\n",
        "\n",
        "> **Synchrony**: multiunit spiking activity quantified by the variance of the spike count histogram (bin width 3 ms) divided by its mean (i.e., the Fano factor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AexCpKU_u-Uz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def firing_rate(spk_neuron, measures_layer, tsim):\n",
        "  #############################################################################\n",
        "  # Firing rates\n",
        "  #############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  freq = []\n",
        "  freq = [float(len(spk_neuron.t[i]))/tsim for i in range(len(spk_neuron))]\n",
        "  spk_neuron['f'] = freq\n",
        "\n",
        "  measures_layer['f'] = spk_neuron.groupby(['layer'], observed=False)['f'].mean()\n",
        "\n",
        "  # boxplot of firing rates by layer\n",
        "  bplot = spk_neuron.boxplot(column = 'f', by = 'layer', showmeans=True,\n",
        "                      vert = False, rot = 30, patch_artist=True, sym='+',\n",
        "                      return_type='dict', grid=False)\n",
        "\n",
        "  [bplot[0]['boxes'][i].set_facecolor(dotcolor[i]) for i in range(0,len(bplot[0]['boxes']))]\n",
        "  [bplot[0]['means'][i].set_markerfacecolor('white') for i in range(0,len(bplot[0]['boxes']))]\n",
        "  [bplot[0]['means'][i].set_markeredgecolor('k') for i in range(0,len(bplot[0]['boxes']))]\n",
        "\n",
        "  plt.title(\"\")\n",
        "  plt.ylabel(\"\")\n",
        "  plt.xlabel('firing rates[Hz]')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7R64L71vN0h"
      },
      "outputs": [],
      "source": [
        "firing_rate(spk_neuron, measures_layer, tsim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8qMmc2J3LjK"
      },
      "source": [
        "<font color=\"green\">**To Do 2-1**</font>: Replace `##YOUR CODE##` with your code to complete the irregularity plotting function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzfN3uHexsEv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def irregularity(spk_neuron, measures_layer):\n",
        "  #############################################################################\n",
        "  # Interspike intervals + coefficient of variation\n",
        "  #############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  # interspike intervals\n",
        "  isi = []\n",
        "  isi = ##YOUR CODE##\n",
        "  raise NotImplementedError()\n",
        "\n",
        "  # coefficient of variation\n",
        "  cv = []\n",
        "  cv = ##YOUR CODE##\n",
        "  raise NotImplementedError()\n",
        "\n",
        "  spk_neuron['cv'] = cv\n",
        "\n",
        "  measures_layer['cv'] = spk_neuron.groupby(['layer'], observed=False)['cv'].mean()\n",
        "\n",
        "  # barplot of mean CV\n",
        "  plt.subplot2grid((3,2),(1,1))\n",
        "  measures_layer['cv'].plot.barh(edgecolor='k' ,color=dotcolor, rot=30, width=0.8)\n",
        "  plt.ylabel(\"\")\n",
        "  plt.xlabel('irregularity')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zi9IwBfM3nr6"
      },
      "outputs": [],
      "source": [
        "#@title Solution To Do 2-1\n",
        "%matplotlib inline\n",
        "\n",
        "def irregularity(spk_neuron, measures_layer):\n",
        "  #############################################################################\n",
        "  # Interspike intervals + coefficient of variation\n",
        "  #############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  # interspike intervals\n",
        "  isi = []\n",
        "  isi = [np.diff(spk_neuron.t[i]) for i in range(len(spk_neuron))]\n",
        "\n",
        "  # coefficient of variation\n",
        "  cv = []\n",
        "  cv = [np.std(isi[i])/np.mean(isi[i]) if len(isi[i])>1 else np.nan\\\n",
        "          for i in range(len(spk_neuron))]\n",
        "  spk_neuron['cv'] = cv\n",
        "\n",
        "  measures_layer['cv'] = spk_neuron.groupby(['layer'], observed=False)['cv'].mean()\n",
        "\n",
        "  # barplot of mean CV\n",
        "  plt.subplot2grid((3,2),(1,1))\n",
        "  measures_layer['cv'].plot.barh(edgecolor='k' ,color=dotcolor, rot=30, width=0.8)\n",
        "  plt.ylabel(\"\")\n",
        "  plt.xlabel('irregularity')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKVKZxq-zaUJ"
      },
      "outputs": [],
      "source": [
        "irregularity(spk_neuron, measures_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8E7sUTlINdW"
      },
      "source": [
        "<font color=\"green\">**To Do 2-2**</font>: Replace `##YOUR CODE##` with your code to complete the synchrony plotting function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oruj5Tmd0agM"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def synchrony(spk_neuron, measures_layer):\n",
        "  #############################################################################\n",
        "  # Synchrony index\n",
        "  #############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  sync = []\n",
        "  # define 3 ms bin\n",
        "  bins = np.arange(0,tsim*1000.0+3.0,3)\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "    ##YOUR CODE##\n",
        "    # 1. Filter out the spiking neurons of this layer from `spk_neuron`\n",
        "    # 2. Use np.histogram to derive the spike counts of each bin from `data`\n",
        "    # 3. Use spiking counts to calculate synchrony. Note that we calculate the\n",
        "    #    sychrony based on the last 500 ms data, so use `count[166:]` (spiking\n",
        "    #    counts data from 498 ms onwards).\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "  measures_layer['sync'] = sync\n",
        "\n",
        "  # barplot of synchrony index\n",
        "  y_pos = np.arange(len(lname))\n",
        "  plt.subplot2grid((3,2),(2,1))\n",
        "  measures_layer['sync'].plot.barh(edgecolor='k' ,color=dotcolor, rot=30, width=0.8)\n",
        "  plt.ylabel(\"\")\n",
        "  plt.xlabel('synchrony')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hPbK-z8HIUvK"
      },
      "outputs": [],
      "source": [
        "#@title Solution To Do 2-2\n",
        "%matplotlib inline\n",
        "\n",
        "def synchrony(spk_neuron, measures_layer):\n",
        "  #############################################################################\n",
        "  # Synchrony index\n",
        "  #############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  sync = []\n",
        "  bins = np.arange(0,tsim*1000.0+3.0,3)\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "      index_sample = spk_neuron.i[spk_neuron.layer.isin([lname[i]])]\n",
        "      count, division = np.histogram(data.t[data.i.isin(index_sample)],bins=bins)\n",
        "      sync.append(np.var(count[166:])/np.mean(count[166:]))\n",
        "\n",
        "  measures_layer['sync'] = sync\n",
        "\n",
        "  # barplot of synchrony index\n",
        "  y_pos = np.arange(len(lname))\n",
        "  plt.subplot2grid((3,2),(2,1))\n",
        "  measures_layer['sync'].plot.barh(edgecolor='k' ,color=dotcolor, rot=30, width=0.8)\n",
        "  plt.ylabel(\"\")\n",
        "  plt.xlabel('synchrony')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRIE2-9O0yBP"
      },
      "outputs": [],
      "source": [
        "synchrony(spk_neuron, measures_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9keKkLVaPGED"
      },
      "source": [
        "We may also plot the histogram to inspect the spiking distribution along the time axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQlUtGyyPQ00"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def spike_histograms(spk_neuron, lname, tsim):\n",
        "    #############################################################################\n",
        "    # Spike count histograms for each layer\n",
        "    #############################################################################\n",
        "    n_layers = len(lname)\n",
        "\n",
        "    fig, axes = plt.subplots(n_layers, 1, figsize=(7.5, 10))  # One subplot per layer\n",
        "\n",
        "    bins = np.arange(0, tsim * 1000.0 + 3.0, 3)\n",
        "\n",
        "    for i in range(len(lname)):\n",
        "      index_sample = spk_neuron.i[spk_neuron.layer.isin([lname[i]])]\n",
        "      count, division = np.histogram(data.t[data.i.isin(index_sample)],bins=bins)\n",
        "\n",
        "      ax = axes[i]\n",
        "      ax.bar(bins[167:], count[166:], width=3, color='blue', edgecolor='k')\n",
        "\n",
        "      ax.set_title(lname[i])\n",
        "      ax.set_xlabel(\"time\")\n",
        "      ax.set_ylabel(\"spike count\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spike_histograms(spk_neuron, lname, tsim)"
      ],
      "metadata": {
        "id": "KS7IpbMe2SZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8MO96Mlju4Y"
      },
      "source": [
        "<font color=\"red\">**To Think 2-2**</font>\n",
        "1. Do the results in alignment with [the stimulation results in the paper](https://academic.oup.com/view-large/figure/80937186/bhs35806.gif)?\n",
        "2. Are our simulated firing rates in agreement with [the experimental results](https://academic.oup.com/view-large/80937194)?\n",
        "3. Compare firing rates of excitatory and inhibitory cells of different layers, which one is higher? What could be the neuroscience implications of it?\n",
        "4. Does the network in general show asychronous irregular (AI) firing behaviour? Consider the irregularity and synchrony data, and compare the raster plot with the following reference.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Beckinetic/SpikeNetwork/master/images/behav_reference.jpg\" width=450>\n",
        "\n",
        "(Brunel, 2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3l8zZc3UqO4"
      },
      "source": [
        "Great! We now have finished every necessary component of this simulation workflow. Now it's time to do more testing on this network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEY424BxWt3P"
      },
      "source": [
        "## 3. Network Robustness Test: Background Input Forms\n",
        "In the network building section we defined different forms of inputs. We are going to replace the layer-specific Poissonian inputs with layer-independent Poissonian inputs (identical input \"intensity\" to every layer), and with layer-specific DC inputs. We are also going to inspect the results with the measures we defined before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Mg8D2kg4j4"
      },
      "source": [
        "### Layer-independent Poissonian Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I6p8fXrxW6RA"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 1 # layer-independent inputs\n",
        "stim = 0 # Poissonian inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, filename=filename(g, bg, '_layer-independent'))\n",
        "gc.collect() #garbage collector to clean memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zZQEly2khkVF"
      },
      "outputs": [],
      "source": [
        "#@title Alternative Simulation Option\n",
        "# run the simulation!\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "# Note. It may take time longer than expected due to variance in initialization\n",
        "!python netRun.py 1 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtplyRKBZrZ7"
      },
      "outputs": [],
      "source": [
        "spk_neuron, measures_layer, data = preprocess(tsim, filename(g, bg, '_layer-independent'), lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "firing_rate(spk_neuron, measures_layer, tsim)\n",
        "irregularity(spk_neuron, measures_layer)\n",
        "synchrony(spk_neuron, measures_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKvWAUNAhBRp"
      },
      "source": [
        "### Layer-specific DC Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdTOSJ1LcyUE"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 1 # DC current inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, filename=filename(g, bg, '_DC'))\n",
        "gc.collect() #garbage collector to clean memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUz6KIqIhuOC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Alternative Simulation Option\n",
        "# run the simulation!\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "# Note. It may take time longer than expected due to variance in initialization\n",
        "!python netRun.py 0 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q8EqBgSc4sz"
      },
      "outputs": [],
      "source": [
        "spk_neuron, measures_layer, data = preprocess(tsim, filename(g, bg, '_DC'), lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "firing_rate(spk_neuron, measures_layer, tsim)\n",
        "irregularity(spk_neuron, measures_layer)\n",
        "synchrony(spk_neuron, measures_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXgrr-uphxRK"
      },
      "source": [
        "<font color=\"red\">**To Think 3-1**</font>: Compare the results with the spontaneous activity simulation (layer-specific Poissonian inputs) results.\n",
        "1. What changes and what features are conserved? Do you find the network robust to the input forms? What could be reasons for it to be/not to be robust?\n",
        "2. What happened to L6e when the inputs become layer-independent (you may also make the raster plot)? Does it give you some implications on the biological realism of the input forms?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DO4LGfmHjlI"
      },
      "source": [
        "## 4. Stimulus Evoked Activity\n",
        "\n",
        "To simulate stimulus-evoked activity, we explicitly model the thalamic input to L4 and L6 by a thalamic population of 902 neurons (Peters and Payne 1993). The thalamic stimulus will be injected from 700 ms to 710 ms."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 1 # DC inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, thal=\"ON\", filename=filename(g, bg, '_thal'))\n",
        "gc.collect() #garbage collector to clean memory"
      ],
      "metadata": {
        "id": "o0SKohfd0j_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Alternative Simulation Option\n",
        "# run the simulation!\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "# Note. It may take time longer than expected due to variance in initialization\n",
        "!python netRun.py 5 1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y2SUCAnME5yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make a slightly modified version of raster plot function to zoom into the moment that the thalamic stimulus transpired."
      ],
      "metadata": {
        "id": "59u0IwNL8unj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdGKqZpyyo4B"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def rasterplot_thal(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample):\n",
        "  ###############################################################################\n",
        "  # Raster plot\n",
        "  ###############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "  plt.gca().set_yticklabels([])\n",
        "  acum_index = 0\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "      index_start = l_bins[i]\n",
        "      index_end = l_bins[i]+int(psample*n_layer_plot[i+1])\n",
        "\n",
        "      x = data.t[data.i.isin(range(index_start,index_end))]\n",
        "      y = data.i[data.i.isin(range(index_start,index_end))] + acum_index - index_start\n",
        "\n",
        "      plt.plot(x,y,'.',markersize=dotsize,color=dotcolor[i])\n",
        "\n",
        "      # layers labels\n",
        "      xpos = tsim*1000.0-312\n",
        "      ypos = acum_index + (index_end-index_start)/2.0\n",
        "      plt.text(xpos,ypos,lname[i],horizontalalignment='center', fontsize=12, rotation=30)\n",
        "\n",
        "\n",
        "      acum_index = acum_index + (index_end-index_start)\n",
        "\n",
        "  plt.xlim(tsim*1000.0-310,tsim*1000.0-290)\n",
        "  plt.ylim(0,acum_index)\n",
        "  plt.xlabel('time [ms]')\n",
        "  plt.ylabel(' ')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spk_neuron, measures_layer, data = preprocess(tsim, filename(g, bg, '_thal'), lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "rasterplot_thal(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)"
      ],
      "metadata": {
        "id": "8DK6Hhrs2tov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Furthermore, we can make a step plot to quantify the spike times of each population during the thalamic input."
      ],
      "metadata": {
        "id": "7W6XpH6WCwWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def stepplot_thal(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample):\n",
        "  spk_count = []\n",
        "  bins = np.arange(0,tsim*1000.0+.5,.5)\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "      index_start = l_bins[i]\n",
        "      index_end = l_bins[i]+int(psample*n_layer_plot[i+1])\n",
        "      count, division = np.histogram(data.t[data.i.isin(np.arange(index_start,index_end))],bins=bins)\n",
        "      #count = sum(np.split(count,int(tsim)))/float(tsim)\n",
        "      spk_count.append([count])\n",
        "\n",
        "  measures_layer['spk_count'] = spk_count\n",
        "\n",
        "  for i in range(0,len(lname),2):\n",
        "      plt.subplot2grid((4,3),(int(i/2),1),colspan=2)\n",
        "      plt.step(np.arange(-10,30,0.5),measures_layer.spk_count[i][0][1380:1460], label=lname[i])\n",
        "      plt.step(np.arange(-10,30,0.5),measures_layer.spk_count[i+1][0][1380:1460], label=lname[i+1])\n",
        "      plt.legend()\n",
        "      if i != 6:\n",
        "          ax = plt.gca()\n",
        "          ax.xaxis.set_visible(False)\n",
        "      else:\n",
        "          ax = plt.gca()\n",
        "          ax.yaxis.set_visible(True)\n",
        "      plt.ylim(0,13)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IeATOG_AA1oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stepplot_thal(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)"
      ],
      "metadata": {
        "id": "2k141TMiBNeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**To Think 4-1**</font>\n",
        "\n",
        "1. Compare the spiking with the spontaneous activities, what are the differences?\n",
        "2. Try to sort out the spiking order of the neurons during the thalamic input. Compare it with the [flow map](https://academic.oup.com/view-large/figure/80937217/bhs35811.gif) in the paper. It's been argued that there is a feed-forward loop from L4 to L2/3 to L5. Do you concur with this view?\n",
        "3. Why are some inhibitory neurons fired after the excitatory neurons' spiking?"
      ],
      "metadata": {
        "id": "QH6HcgAD87-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\">**To Do 4-1**</font>: Modify the network parameters to remove the thalamic inputs to L6 and only preserve the input to L4. Run the simulation and make necessary plots to draw your conclusion."
      ],
      "metadata": {
        "id": "bdtSUid2DMp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##YOUR CODE##"
      ],
      "metadata": {
        "id": "s2V5LdJ3ONwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution To Do 4-1 (Code Only)\n",
        "\n",
        "# Modify the prob. connection table\n",
        "#          From 2/3e    2/3i   4e     4i     5e     5i      6e     6i      Th        To\n",
        "table = array([[0.101,  0.169, 0.044, 0.082, 0.032, 0.,     0.008, 0.,     0.    ], #2/3e\n",
        "               [0.135,  0.137, 0.032, 0.052, 0.075, 0.,     0.004, 0.,     0.    ], #2/3i\n",
        "               [0.008,  0.006, 0.050, 0.135, 0.007, 0.0003, 0.045, 0.,     0.0983], #4e\n",
        "               [0.069,  0.003, 0.079, 0.160, 0.003, 0.,     0.106, 0.,     0.0619], #4i\n",
        "               [0.100,  0.062, 0.051, 0.006, 0.083, 0.373,  0.020, 0.,     0.    ], #5e\n",
        "               [0.055,  0.027, 0.026, 0.002, 0.060, 0.316,  0.009, 0.,     0.    ], #5i\n",
        "               [0.016,  0.007, 0.021, 0.017, 0.057, 0.020,  0.040, 0.225,  0.    ], #6e\n",
        "               [0.036,  0.001, 0.003, 0.001, 0.028, 0.008,  0.066, 0.144,  0.    ]])#6i\n",
        "\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 1 # DC inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, thal=\"ON\", filename=filename(g, bg, '_thal_L4'))\n",
        "gc.collect() #garbage collector to clean memory\n",
        "\n",
        "spk_neuron, measures_layer, data = preprocess(tsim, filename(g, bg, '_thal_L4'), lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "rasterplot_thal(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "stepplot_thal(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)"
      ],
      "metadata": {
        "id": "Z2qHkKtsHoCS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Prefrontal Top-Down Stimulus\n",
        "\n",
        "<font color=\"green\">**To Do 4-1**</font>: Modify the network parameters, `PDnet`, `runParams` and other relevant components to simulate prefrontal top-down stimulus to this network. You may use the thalamic inputs as reference. Make raster plot and step plot to illustrate your results. Compare the results with previous thalamic stimulus results and spontaneous activity results.\n",
        "\n",
        "Some parameters you may need:\n",
        "\n",
        "**PFC Neuron Number**: 1000\n",
        "\n",
        "**PFC Connection Probability**:\n",
        "```\n",
        "# Prob. connection table\n",
        "#          From 2/3e    2/3i   4e     4i     5e     5i      6e     6i      Th      Pfc      To\n",
        "table = array([[0.101,  0.169, 0.044, 0.082, 0.032, 0.,     0.008, 0.,     0.,     0.0900], #2/3e\n",
        "               [0.135,  0.137, 0.032, 0.052, 0.075, 0.,     0.004, 0.,     0.,     0.0550], #2/3i\n",
        "               [0.008,  0.006, 0.050, 0.135, 0.007, 0.0003, 0.045, 0.,     0.0983, 0.    ], #4e\n",
        "               [0.069,  0.003, 0.079, 0.160, 0.003, 0.,     0.106, 0.,     0.0619, 0.    ], #4i\n",
        "               [0.100,  0.062, 0.051, 0.006, 0.083, 0.373,  0.020, 0.,     0.,     0.0500], #5e\n",
        "               [0.055,  0.027, 0.026, 0.002, 0.060, 0.316,  0.009, 0.,     0.,     0.0200], #5i\n",
        "               [0.016,  0.007, 0.021, 0.017, 0.057, 0.020,  0.040, 0.225,  0.0512, 0.0500], #6e\n",
        "               [0.036,  0.001, 0.003, 0.001, 0.028, 0.008,  0.066, 0.144,  0.0196, 0.0200]])#6i\n",
        "```\n",
        "\n",
        "**Rates**: 50Hz\n",
        "\n",
        "**Stimulus Time**: 500ms ~ 800ms"
      ],
      "metadata": {
        "id": "c5009504JHIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##YOUR CODE##"
      ],
      "metadata": {
        "id": "1PNVw_BIYd9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Solution To Do 5-1 (Code Only)\n",
        "\n",
        "###############################################################################\n",
        "# Network parameters\n",
        "###############################################################################\n",
        "# Population size per layer\n",
        "#          2/3e   2/3i   4e    4i    5e    5i    6e     6i    Th   Pfc\n",
        "n_layer = [20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948, 902, 1000]\n",
        "\n",
        "# Total cortical Population\n",
        "N = sum(n_layer[:-1])\n",
        "\n",
        "# Number of neurons accumulated\n",
        "nn_cum = [0]\n",
        "nn_cum.extend(cumsum(n_layer))\n",
        "\n",
        "# Prob. connection table\n",
        "#          From 2/3e    2/3i   4e     4i     5e     5i      6e     6i      Th      Pfc      To\n",
        "table = array([[0.101,  0.169, 0.044, 0.082, 0.032, 0.,     0.008, 0.,     0.,     0.0900], #2/3e\n",
        "               [0.135,  0.137, 0.032, 0.052, 0.075, 0.,     0.004, 0.,     0.,     0.0550], #2/3i\n",
        "               [0.008,  0.006, 0.050, 0.135, 0.007, 0.0003, 0.045, 0.,     0.0983, 0.    ], #4e\n",
        "               [0.069,  0.003, 0.079, 0.160, 0.003, 0.,     0.106, 0.,     0.0619, 0.    ], #4i\n",
        "               [0.100,  0.062, 0.051, 0.006, 0.083, 0.373,  0.020, 0.,     0.,     0.0500], #5e\n",
        "               [0.055,  0.027, 0.026, 0.002, 0.060, 0.316,  0.009, 0.,     0.,     0.0200], #5i\n",
        "               [0.016,  0.007, 0.021, 0.017, 0.057, 0.020,  0.040, 0.225,  0.0512, 0.0500], #6e\n",
        "               [0.036,  0.001, 0.003, 0.001, 0.028, 0.008,  0.066, 0.144,  0.0196, 0.0200]])#6i\n",
        "\n",
        "# Synapses parameters\n",
        "d_ex = 1.5*ms      \t# Excitatory delay\n",
        "std_d_ex = 0.75*ms \t# Std. Excitatory delay\n",
        "d_in = 0.80*ms      # Inhibitory delay\n",
        "std_d_in = 0.4*ms  \t# Std. Inhibitory delay\n",
        "tau_syn = 0.5*ms    # Post-synaptic current time constant\n",
        "\n",
        "# Layer-specific background input\n",
        "bg_layer_specific = array([1600, 1500 ,2100, 1900, 2000, 1900, 2900, 2100])\n",
        "\n",
        "# Layer-independent background input\n",
        "bg_layer_independent = array([2000, 1850 ,2000, 1850, 2000, 1850, 2000, 1850])\n",
        "\n",
        "\n",
        "def PDnet(NeuronGroup, stim, bg_type, w_ex, g, bg_freq, nsyn_type, thal, pfc):\n",
        "    # P and D are the initials of the authors of the paper\n",
        "\n",
        "    w_ex = w_ex*pA\t\t   \t# excitatory synaptic weight\n",
        "    std_w_ex = 0.1*w_ex     # standard deviation weight\n",
        "\n",
        "    pop = [] # Stores NeuronGroups, one for each population\n",
        "    for r in range(0, 9):\n",
        "        pop.append(NeuronGroup[nn_cum[r]:nn_cum[r+1]])\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating synapse connections\n",
        "    ###########################################################################\n",
        "\n",
        "    syn_model = '''\n",
        "                w:amp\t\t\t# synaptic weight\n",
        "                '''\n",
        "\n",
        "    # equations executed only when presynaptic spike occurs:\n",
        "    # for excitatory connections\n",
        "    pre_eq = '''\n",
        "            I_post += w\n",
        "            '''\n",
        "\n",
        "    con = [] # Stores connections\n",
        "\n",
        "    ###########################################################################\n",
        "    # Connecting neurons\n",
        "    ###########################################################################\n",
        "\n",
        "    pre_index = [] # presynaptic neuron index\n",
        "    post_index = [] # postsynaptic neuron index\n",
        "\n",
        "    # c: column (presynaptic neurons)\n",
        "    # r: row (postsynaptic neurons)\n",
        "    for c in range(0, 8):\n",
        "        for r in range(0, 8):\n",
        "\n",
        "            if (nsyn_type==0):\n",
        "                # number of synapses calculated with the original equation\n",
        "                nsyn = int(log(1.0-table[r][c])/log(1.0 - (1.0/float(n_layer[c]*n_layer[r]))))\n",
        "            elif (nsyn_type==1):\n",
        "                # number of synapses calculated with the Taylor series approximation\n",
        "                nsyn = int(n_layer[c]*n_layer[r]*table[r][c])\n",
        "            pre_index = randint(n_layer[c], size=nsyn)\n",
        "            post_index = randint(n_layer[r], size=nsyn)\n",
        "\n",
        "            # assign weights to the synapses\n",
        "            if nsyn<1:\n",
        "                pass\n",
        "            else:\n",
        "                # Excitatory connections\n",
        "                if (c % 2) == 0:\n",
        "                    # Synaptic weight from L4e to L2/3e is doubled\n",
        "                    if c == 2 and r == 0:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = '2.0*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    else:\n",
        "                        con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                        con[-1].connect(i = pre_index, j = post_index)\n",
        "                        con[-1].w = 'clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_ex + std_d_ex*randn(), 0.1*ms, d_ex*inf)'\n",
        "\n",
        "                # Inhibitory connections\n",
        "                else:\n",
        "                    con.append(Synapses(pop[c], pop[r], model=syn_model, on_pre=pre_eq))\n",
        "                    con[-1].connect(i = pre_index, j = post_index)\n",
        "                    con[-1].w = '-g*clip((w_ex + std_w_ex*randn()),w_ex*0.0, w_ex*inf)'\n",
        "                    con[-1].delay = 'clip(d_in + std_d_in*randn(), 0.1*ms, d_in*inf)'\n",
        "\n",
        "    ###########################################################################\n",
        "    # Setting background input values\n",
        "    ###########################################################################\n",
        "\n",
        "    # Background number per layer\n",
        "    if bg_type == 0:\n",
        "        # layer-specific:\n",
        "        bg_layer = bg_layer_specific\n",
        "    elif bg_type == 1:\n",
        "        # layer-independent:\n",
        "        bg_layer = bg_layer_independent\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating poissonian and DC-current background inputs\n",
        "    ###########################################################################\n",
        "\n",
        "    bg_in  = []\n",
        "    if (stim==0):\n",
        "        for r in range(0, 8):\n",
        "            bg_in.append(PoissonInput(pop[r], 'I', bg_layer[r], bg_freq*Hz, weight=w_ex))\n",
        "\n",
        "    # DC-current normalized by population\n",
        "    if (stim == 1):\n",
        "        for r in range(0, 8):\n",
        "            NeuronGroup.Iext[pop[r]] = 0.3512*pA*bg_layer[r]\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating thalamic neurons as poissonian inputs\n",
        "    ###########################################################################\n",
        "\n",
        "    thal_con = []\n",
        "    thal_input = []\n",
        "    if thal==\"ON\":\n",
        "        thal_input = PoissonGroup(n_layer[8], rates=120.0*Hz) #from PD paper: rates=15Hz\n",
        "        for r in range(0,8):\n",
        "            thal_con.append(Synapses(thal_input, pop[r], model=syn_model, on_pre=pre_eq))\n",
        "            thal_con[-1].connect(p=table[r][8])\n",
        "            thal_con[-1].w = 0.0\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating prefrontal neurons as poissonian inputs\n",
        "    ###########################################################################\n",
        "\n",
        "    pfc_con = []\n",
        "    pfc_input = []\n",
        "    if pfc==\"ON\":\n",
        "        pfc_input = PoissonGroup(n_layer[9], rates=50.0*Hz) #from PD paper: rates=15Hz\n",
        "        for r in range(0,8):\n",
        "            pfc_con.append(Synapses(pfc_input, pop[r], model=syn_model, on_pre=pre_eq))\n",
        "            pfc_con[-1].connect(p=table[r][9])\n",
        "            pfc_con[-1].w = 0.0\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating spike monitors\n",
        "    ###########################################################################\n",
        "\n",
        "    smon_net = SpikeMonitor(NeuronGroup)\n",
        "\n",
        "    return pop, con, bg_in, smon_net, thal_input ,thal_con, pfc_input, pfc_con\n",
        "\n",
        "def runParams(tsim=1.0, bg_type=0, stim=0, w_ex=87.8, g=4.0, bg_freq=8.0, nsyn_type=0, thal='OFF', pfc='OFF', filename=None):\n",
        "\n",
        "    ###########################################################################\n",
        "    # Simulation parameters\n",
        "    ###########################################################################\n",
        "    defaultclock.dt = 0.1*ms    # timestep of numerical integration method\n",
        "\n",
        "    # neuron model\n",
        "    eqs = LIFmodel\n",
        "    reset = resetLIF\n",
        "    tau_m, tau_ref, Cm, v_r, v_th = LIFparams()\n",
        "\n",
        "    ###########################################################################\n",
        "    # Creating neurons\n",
        "    ###########################################################################\n",
        "    neurons = NeuronGroup(N, eqs, threshold='v>v_th', reset=reset, \\\n",
        "                            method='linear', refractory=tau_ref)\n",
        "\n",
        "    # seting initial values for membrane potential and currents\n",
        "    neurons.v = '-58.0*mV + 10.0*mV*randn()'\n",
        "    neurons.I = 0.0*pA      # initial value for synaptic currents\n",
        "    neurons.Iext = 0.0*pA   # constant external current\n",
        "\n",
        "    pop, con, bg_in, smon_net, thal_input, thal_con, pfc_input, pfc_con = PDnet(neurons, stim, \\\n",
        "                                            bg_type, w_ex, g, bg_freq, nsyn_type, thal, pfc)\n",
        "\n",
        "    ###########################################################################\n",
        "    # Running the simulation\n",
        "    ###########################################################################\n",
        "    net = Network(collect())\n",
        "\n",
        "    if (thal == 'OFF' and pfc == 'OFF'):\n",
        "        net.add(neurons,pop, con, bg_in)    # Adding objects to the simulation\n",
        "        net.run(tsim*second, report='stdout')\n",
        "\n",
        "    elif (thal == 'ON'):\n",
        "        w_thal = w_ex*pA            # excitatory synaptic weight from thalamus\n",
        "        std_w_thal = w_thal*0.1     # standard deviation weigth\n",
        "        net.add(neurons,pop, con, bg_in, thal_input, thal_con)    # Adding objects to the simulation\n",
        "\n",
        "        for repeat in range(0,int(tsim)):\n",
        "            net.run(0.7*second,report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "            # Adding thalamic input\n",
        "            for r in range(0,8):\n",
        "                thal_con[r].w = 'clip((w_thal + std_w_thal*randn()),w_thal*0.0, w_thal*inf)'\n",
        "            net.run(0.01*second, report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "            # Removing thalamic input\n",
        "            for r in range(0,8):\n",
        "                thal_con[r].w = 0\n",
        "            net.run(0.29*second, report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "    elif (pfc == 'ON'):\n",
        "        w_pfc = w_ex*pA            # excitatory synaptic weight from prefrontal cortex\n",
        "        std_w_pfc = w_pfc*0.1     # standard deviation weigth\n",
        "        net.add(neurons,pop, con, bg_in, pfc_input, pfc_con)    # Adding objects to the simulation\n",
        "\n",
        "        for repeat in range(0,int(tsim)):\n",
        "            net.run(0.5*second,report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "            # Adding thalamic input\n",
        "            for r in range(0,8):\n",
        "                pfc_con[r].w = 'clip((w_pfc + std_w_pfc*randn()),w_pfc*0.0, w_pfc*inf)'\n",
        "            net.run(0.3*second, report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "            # Removing thalamic input\n",
        "            for r in range(0,8):\n",
        "                pfc_con[r].w = 0\n",
        "            net.run(0.2*second, report='stdout')\n",
        "            gc.collect()    #garbage collector to clean memory\n",
        "\n",
        "\n",
        "    ###########################################################################\n",
        "    # Saving raster plot\n",
        "    ###########################################################################\n",
        "    savetxt(filename, c_[smon_net.i,smon_net.t/ms],fmt=\"%i %.2f\")\n",
        "\n",
        "def rasterplot_pfc(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample):\n",
        "  ###############################################################################\n",
        "  # Raster plot\n",
        "  ###############################################################################\n",
        "  plt.figure(figsize=(7.5,10))\n",
        "  plt.gca().set_yticklabels([])\n",
        "  acum_index = 0\n",
        "\n",
        "  # graphs color codes: different colors for different layers\n",
        "  dotsize = 2.5\n",
        "  dotcolor = np.array([[0.0, 0.0, 255.0],\n",
        "                      [102.0, 178.0, 255.0],\n",
        "                      [255.0, 128.0, 0.0],\n",
        "                      [255.0, 178.0, 102.0],\n",
        "                      [0.0,   128.0, 0.0],\n",
        "                      [153.0, 255.0, 153.0],\n",
        "                      [255.0, 0.0,   0.0],\n",
        "                      [255.0, 153.0, 153.0]])/255.0\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "      index_start = l_bins[i]\n",
        "      index_end = l_bins[i]+int(psample*n_layer_plot[i+1])\n",
        "\n",
        "      x = data.t[data.i.isin(range(index_start,index_end))]\n",
        "      y = data.i[data.i.isin(range(index_start,index_end))] + acum_index - index_start\n",
        "\n",
        "      plt.plot(x,y,'.',markersize=dotsize,color=dotcolor[i])\n",
        "\n",
        "      # layers labels\n",
        "      xpos = tsim*1000.0-520\n",
        "      ypos = acum_index + (index_end-index_start)/2.0\n",
        "      plt.text(xpos,ypos,lname[i],horizontalalignment='center', fontsize=12, rotation=30)\n",
        "\n",
        "\n",
        "      acum_index = acum_index + (index_end-index_start)\n",
        "\n",
        "  plt.xlim(tsim*1000.0-510,tsim*1000.0-200)\n",
        "  plt.ylim(0,acum_index)\n",
        "  plt.xlabel('time [ms]')\n",
        "  plt.ylabel(' ')\n",
        "  plt.gca().invert_yaxis()\n",
        "  plt.show()\n",
        "\n",
        "def stepplot_pfc(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample):\n",
        "  spk_count = []\n",
        "  bins = np.arange(0,tsim*1000.0+.5,.5)\n",
        "\n",
        "  for i in range(len(lname)):\n",
        "      index_start = l_bins[i]\n",
        "      index_end = l_bins[i]+int(psample*n_layer_plot[i+1])\n",
        "      count, division = np.histogram(data.t[data.i.isin(np.arange(index_start,index_end))],bins=bins)\n",
        "      #count = sum(np.split(count,int(tsim)))/float(tsim)\n",
        "      spk_count.append([count])\n",
        "\n",
        "  measures_layer['spk_count'] = spk_count\n",
        "\n",
        "  for i in range(0,len(lname),2):\n",
        "      plt.subplot2grid((4,3),(int(i/2),1),colspan=2)\n",
        "      plt.step(np.arange(-10,300,0.5),measures_layer.spk_count[i][0][980:1600], label=lname[i])\n",
        "      plt.step(np.arange(-10,300,0.5),measures_layer.spk_count[i+1][0][980:1600], label=lname[i+1])\n",
        "      plt.legend()\n",
        "      if i != 6:\n",
        "          ax = plt.gca()\n",
        "          ax.xaxis.set_visible(False)\n",
        "      else:\n",
        "          ax = plt.gca()\n",
        "          ax.yaxis.set_visible(True)\n",
        "      plt.ylim(0,13)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 1 # DC inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, pfc=\"ON\", filename=filename(g, bg, '_pfc'))\n",
        "gc.collect() #garbage collector to clean memory\n",
        "\n",
        "spk_neuron, measures_layer, data = preprocess(tsim, filename(g, bg, '_pfc'), lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "rasterplot_pfc(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)\n",
        "stepplot_pfc(spk_neuron, tsim, lname, n_layer_plot, l_bins, N, psample, n_sample)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "50c_zHJ9RKfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graded Assignment: In Search for a Good Model\n",
        "\n",
        "*Note*. This is a take-home assignment. You are not required to work on it during the in-class tutorial.\n",
        "\n",
        "After running through the tutorial, we have built a spike network from sractch and studied its spontaneous activities, tested its robustness, and investigated the effects of transient stimuli. Standing upon the giant's shoulder, one wonders: could this model be any better?"
      ],
      "metadata": {
        "id": "lqQ0AiRUK8G9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**To Think A1**</font>: To evaluate the goodness of a neural model, what do you think that are the desiderata? List at least 3 criteria. (3 points)"
      ],
      "metadata": {
        "id": "LGbRc84nBFck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We defined lots of parameters and equations, and all of them might be subject to optimization. In the rest of the assignment, we will reconsider several parameters in this network."
      ],
      "metadata": {
        "id": "YBMbQMhaDa9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Synapse and Neuron Number\n",
        "\n",
        "We have two aforementioned equations to calculate the synapse number between two neuronal populations:\n",
        "$$\n",
        "K = \\ln(C_a) / \\ln(1 - (1 - \\frac{1}{N^{pre}N^{post}}))\n",
        "$$\n",
        "and\n",
        "$$\n",
        "K = \\frac{C_a}{N^{pre}N^{post}}\n",
        "$$\n",
        "\n",
        "The latter is the Taylor series approximation of the first equation. Using different equations will change the synapse number hence the network structure. We will simulate two networks created with different synapse number equations."
      ],
      "metadata": {
        "id": "4wLi_yBQqovJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\">**To Do A1**</font>: Compare the synapse numbers calculated by either equation. Display the changes in synapse numbers and report your finding (2 point)."
      ],
      "metadata": {
        "id": "4QnJSCUJIDMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##YOUR CODE##"
      ],
      "metadata": {
        "id": "e3HYCPlVPCFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are testing whether using different equations alters our network in its behaviour. Let's run the simulations. You may notice the simulations are very RAM-taxing process, does the new equation implementation make the situation better?"
      ],
      "metadata": {
        "id": "OLNf-xDQPFyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### No Synapse Number Approximation (Default Setting)"
      ],
      "metadata": {
        "id": "3_ZFFjTmt0ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 0 # Poissonian inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, nsyn_type=0, filename=filename(g, bg, '_noapprox'))\n",
        "gc.collect() #garbage collector to clean memory"
      ],
      "metadata": {
        "id": "ZwZSDIVCrZ4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Approximated Synapse Number"
      ],
      "metadata": {
        "id": "xARSQ4jJt6yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 0 # Poissonian inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, nsyn_type=1, filename=filename(g, bg, '_approx'))\n",
        "gc.collect() #garbage collector to clean memory"
      ],
      "metadata": {
        "id": "b0H8jTbmsgxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kolmogorov-Smirnov Test\n",
        "\n",
        "We utilize the non-parametric Kolmogorov-Smirnov statistics to quantify the difference in the firing rates and coefficient of variance."
      ],
      "metadata": {
        "id": "vWOeOwBfkPYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title KS Test Function\n",
        "%matplotlib inline\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "def ks_test(tsim):\n",
        "\n",
        "    ###############################################################################\n",
        "    # Filenames\n",
        "    ###############################################################################\n",
        "    filename = (['../data/data_raster_g4.0_bgrate8.0_approx.dat',\\\n",
        "                '../data/data_raster_g4.0_bgrate8.0_noapprox.dat'])\n",
        "\n",
        "    ###############################################################################\n",
        "    # Parameters\n",
        "    ###############################################################################\n",
        "\n",
        "    n = 77169 # total number of neurons\n",
        "\n",
        "    # cortical layer labels: e for excitatory; i for inhibitory\n",
        "    lname = ['L23e', 'L23i', 'L4e', 'L4i', 'L5e', 'L5i','L6e', 'L6i']\n",
        "\n",
        "    # number of neurons by layer\n",
        "    n_layer = [0, 20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948];\n",
        "    l_bins = np.cumsum(n_layer) # cumulative number of neurons by layer\n",
        "\n",
        "    # dataframe to store CV's and firing rates\n",
        "    measures = pd.DataFrame()\n",
        "\n",
        "    for k in range(0,2):\n",
        "\n",
        "        # loading data\n",
        "        data = pd.read_csv(filename[k], sep=\" \", header=None, names=['i','t'])\n",
        "\n",
        "        # grouping spiking times for each neuron\n",
        "        keys,values = data.sort_values(['i','t']).values.T\n",
        "        ukeys,index=np.unique(keys,True)\n",
        "        arrays=np.split(values,index[1:])\n",
        "        spk_neuron = pd.DataFrame({'i':ukeys,'t':[list(a) for a in arrays]})\n",
        "\n",
        "        # creating a flag to identify cortical layers\n",
        "        spk_neuron['layer'] = pd.cut(spk_neuron['i'], l_bins, labels=lname, right=False)\n",
        "        data['layer'] = pd.cut(data['i'], l_bins, labels=lname, right=False)\n",
        "\n",
        "        # cleaning variables\n",
        "        del keys, values, ukeys, index, arrays\n",
        "\n",
        "        ###############################################################################\n",
        "        # Interspike intervals + coefficient of variation\n",
        "        ###############################################################################\n",
        "        # interspike intervals\n",
        "        isi = []\n",
        "        isi = [np.diff(spk_neuron.t[i]) for i in range(len(spk_neuron))]\n",
        "\n",
        "        # coefficient of variation\n",
        "        aux = []\n",
        "        aux = [np.std(isi[i])/np.mean(isi[i]) if len(isi[i])>1 else np.nan\\\n",
        "                for i in range(len(spk_neuron))]\n",
        "\n",
        "        cv = np.zeros(n)*np.nan\n",
        "        cv[spk_neuron.i.astype(int)] = aux\n",
        "\n",
        "        if k == 1:\n",
        "            measures['cv_noaprox'] = cv\n",
        "        else:\n",
        "            measures['cv_aprox'] = cv\n",
        "\n",
        "        ###############################################################################\n",
        "        # Firing rates\n",
        "        ###############################################################################\n",
        "        aux = []\n",
        "        aux = [float(len(spk_neuron.t[i]))/tsim for i in range(len(spk_neuron))]\n",
        "\n",
        "        freq = np.zeros(n)\n",
        "        freq[spk_neuron.i.astype(int)] = aux\n",
        "\n",
        "        if k == 1:\n",
        "            measures['f_noaprox'] = freq\n",
        "        else:\n",
        "            measures['f_aprox'] = freq\n",
        "\n",
        "        # cleaning variables\n",
        "        del data, spk_neuron\n",
        "\n",
        "    measures['layer'] = pd.cut(measures.index, l_bins, labels=lname, right=False)\n",
        "\n",
        "    # arrays to store the p-value from Kolmogorov-Smirnov test\n",
        "    ks_cv = np.zeros(8)\n",
        "    ks_f = np.zeros(8)\n",
        "\n",
        "    p_cv = np.zeros(8)\n",
        "    p_f = np.zeros(8)\n",
        "\n",
        "    # create figures to plot cummulative histograms\n",
        "    fig1, ax1 = plt.subplots(nrows=2, ncols=4, figsize=(10,6))\n",
        "    fig2, ax2 = plt.subplots(nrows=2, ncols=4, figsize=(10,6))\n",
        "\n",
        "    for i in range(0,8):\n",
        "\n",
        "        # grid positions for the graph\n",
        "        xgrid = int(i%2)\n",
        "        ygrid = int(i/2)\n",
        "\n",
        "        ################################################################\n",
        "        # CV's distribution comparison\n",
        "        ################################################################\n",
        "        plt.figure(1)\n",
        "        plt.subplot2grid((2,4),(xgrid,ygrid))\n",
        "        plt.title(lname[i])\n",
        "\n",
        "        # excluding NAN values\n",
        "        aux1 = measures.groupby('layer')['cv_aprox'].get_group(lname[i])\n",
        "        aux1 = aux1[~np.isnan(aux1)]\n",
        "\n",
        "        aux2 = measures.groupby('layer')['cv_noaprox'].get_group(lname[i])\n",
        "        aux2 = aux2[~np.isnan(aux2)]\n",
        "\n",
        "        # CV's histograms\n",
        "        cv1,edges1 = np.histogram(aux1,bins='sqrt',range=(0,2.0))\n",
        "        cv2,edges2 = np.histogram(aux2,bins=np.linspace(0,2.0,len(edges1)))\n",
        "\n",
        "        # cummulated histograms\n",
        "        cv1 = np.cumsum(cv1)\n",
        "        cv2 = np.cumsum(cv2)\n",
        "\n",
        "        # normalizing cummulated histograms\n",
        "        cv1 = cv1/float(max(cv1))\n",
        "        cv2 = cv2/float(max(cv2))\n",
        "\n",
        "        # plot data\n",
        "        plt.plot(edges1[:-1],cv1,'--', label='Approximated')\n",
        "        plt.plot(edges2[:-1],cv2,label='Not Approximated')\n",
        "        if (i==0): plt.legend(loc=4)\n",
        "        if (i>1): plt.yticks([])\n",
        "        if (i%2==0): plt.xticks([])\n",
        "        plt.autoscale(enable=True, axis='x', tight=True)\n",
        "\n",
        "        # Kolmogorov-Smirnov statistical test\n",
        "        ks_cv[i], p_cv[i] = ks_2samp(cv1, cv2)\n",
        "\n",
        "        del aux1, aux2, cv1, cv2\n",
        "\n",
        "        ################################################################\n",
        "        # firing rate distribution comparison\n",
        "        ################################################################\n",
        "        plt.figure(2)\n",
        "        plt.subplot2grid((2,4),(xgrid,ygrid))\n",
        "        plt.title(lname[i])\n",
        "\n",
        "        # excluding NAN values\n",
        "        aux1 = measures.groupby('layer')['f_aprox'].get_group(lname[i])\n",
        "        aux1 = aux1[~np.isnan(aux1)]\n",
        "\n",
        "        aux2 = measures.groupby('layer')['f_noaprox'].get_group(lname[i])\n",
        "        aux2 = aux2[~np.isnan(aux2)]\n",
        "\n",
        "        # firing rate histograms\n",
        "        f1,edges1 = np.histogram(aux1,bins='sqrt',range=(0,max(aux1)))\n",
        "        f2,edges2 = np.histogram(aux2,bins=np.linspace(0,max(aux1),len(edges1)))\n",
        "\n",
        "        # cummulated histograms\n",
        "        f1 = np.cumsum(f1)\n",
        "        f2 = np.cumsum(f2)\n",
        "\n",
        "        # normalizing cummulated histograms\n",
        "        f1 = f1/float(max(f1))\n",
        "        f2 = f2/float(max(f2))\n",
        "\n",
        "        # plot data\n",
        "        plt.plot(edges1[:-1],f1,'--', label='Approximated')\n",
        "        plt.plot(edges1[:-1],f2,label='Not Approximated')\n",
        "        if (i==0): plt.legend(loc=4)\n",
        "        if (i>1): plt.yticks([])\n",
        "        plt.autoscale(enable=True, axis='x', tight=True)\n",
        "\n",
        "        # Kolmogorov-Smirnov statistical test\n",
        "        ks_f[i], p_f[i] = ks_2samp(f1, f2)\n",
        "\n",
        "        del aux1, aux2, f1, f2\n",
        "\n",
        "    # formating figures:ks_2samp\n",
        "    plt.figure(1)\n",
        "    fig1.add_subplot(111, frameon=False)\n",
        "    plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
        "    plt.xlabel('CV', fontsize=12, labelpad=10)\n",
        "    plt.ylabel('cumulative distribution',fontsize=12, labelpad=12)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.figure(2)\n",
        "    fig2.add_subplot(111, frameon=False)\n",
        "    plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
        "    plt.xlabel('firing rate [Hz]', fontsize=12, labelpad=10)\n",
        "    plt.ylabel('cumulative distribution',fontsize=12, labelpad=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return ks_cv, ks_f, p_cv, p_f\n",
        "\n",
        "def ks_test_n_neuron(tsim, scale=0.95):\n",
        "\n",
        "    ###############################################################################\n",
        "    # Filenames\n",
        "    ###############################################################################\n",
        "    filename = (['../data/data_raster_g4.0_bgrate8.0_less.dat',\\\n",
        "                '../data/data_raster_g4.0_bgrate8.0default.dat'])\n",
        "\n",
        "    ###############################################################################\n",
        "    # Parameters\n",
        "    ###############################################################################\n",
        "\n",
        "    # cortical layer labels: e for excitatory; i for inhibitory\n",
        "    lname = ['L23e', 'L23i', 'L4e', 'L4i', 'L5e', 'L5i','L6e', 'L6i']\n",
        "\n",
        "    # dataframe to store CV's and firing rates\n",
        "    measures_less = pd.DataFrame()\n",
        "    measures_default = pd.DataFrame()\n",
        "\n",
        "    for k in range(0,2):\n",
        "\n",
        "      if k == 0:\n",
        "        n_layer = np.multiply([0, 20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948], scale).astype(int).tolist()\n",
        "        n = sum(n_layer)\n",
        "        l_bins = np.cumsum(n_layer)\n",
        "      elif k == 1:\n",
        "        n_layer = [0, 20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948]\n",
        "        n = sum(n_layer)\n",
        "        l_bins = np.cumsum(n_layer)\n",
        "\n",
        "      # loading data\n",
        "      data = pd.read_csv(filename[k], sep=\" \", header=None, names=['i','t'])\n",
        "\n",
        "      # grouping spiking times for each neuron\n",
        "      keys,values = data.sort_values(['i','t']).values.T\n",
        "      ukeys,index=np.unique(keys,True)\n",
        "      arrays=np.split(values,index[1:])\n",
        "      spk_neuron = pd.DataFrame({'i':ukeys,'t':[list(a) for a in arrays]})\n",
        "\n",
        "      # creating a flag to identify cortical layers\n",
        "      spk_neuron['layer'] = pd.cut(spk_neuron['i'], l_bins, labels=lname, right=False)\n",
        "      data['layer'] = pd.cut(data['i'], l_bins, labels=lname, right=False)\n",
        "\n",
        "      # cleaning variables\n",
        "      del keys, values, ukeys, index, arrays\n",
        "\n",
        "      print(f\"k={k}, spk_neuron.shape={spk_neuron.shape}, n={n}\")\n",
        "\n",
        "      ###############################################################################\n",
        "      # Interspike intervals + coefficient of variation\n",
        "      ###############################################################################\n",
        "      # interspike intervals\n",
        "      isi = []\n",
        "      isi = [np.diff(spk_neuron.t[i]) for i in range(len(spk_neuron))]\n",
        "\n",
        "      # coefficient of variation\n",
        "      aux = []\n",
        "      aux = [np.std(isi[i])/np.mean(isi[i]) if len(isi[i])>1 else np.nan\\\n",
        "              for i in range(len(spk_neuron))]\n",
        "\n",
        "      cv = np.zeros(n)*np.nan\n",
        "      print(f\"cv.shape={cv.shape}, aux.shape={len(aux)}\")\n",
        "      print(f\"spk_neuron.i.shape={spk_neuron.i.shape}\")\n",
        "      cv[spk_neuron.i.astype(int)] = aux\n",
        "\n",
        "      if k == 1:\n",
        "          measures_default['cv_default'] = cv\n",
        "      else:\n",
        "          measures_less['cv_less'] = cv\n",
        "\n",
        "      ###############################################################################\n",
        "      # Firing rates\n",
        "      ###############################################################################\n",
        "      aux = []\n",
        "      aux = [float(len(spk_neuron.t[i]))/tsim for i in range(len(spk_neuron))]\n",
        "\n",
        "      freq = np.zeros(n)\n",
        "      freq[spk_neuron.i.astype(int)] = aux\n",
        "\n",
        "      if k == 1:\n",
        "          measures_default['f_default'] = freq\n",
        "      else:\n",
        "          measures_less['f_less'] = freq\n",
        "\n",
        "      # cleaning variables\n",
        "      del data, spk_neuron\n",
        "\n",
        "    measures_default['layer'] = pd.cut(measures_default.index, l_bins, labels=lname, right=False)\n",
        "    measures_less['layer'] = pd.cut(measures_less.index, l_bins, labels=lname, right=False)\n",
        "\n",
        "    # arrays to store the p-value from Kolmogorov-Smirnov test\n",
        "    ks_cv = np.zeros(8)\n",
        "    ks_f = np.zeros(8)\n",
        "\n",
        "    p_cv = np.zeros(8)\n",
        "    p_f = np.zeros(8)\n",
        "\n",
        "    # create figures to plot cummulative histograms\n",
        "    fig1, ax1 = plt.subplots(nrows=2, ncols=4, figsize=(10,6))\n",
        "    fig2, ax2 = plt.subplots(nrows=2, ncols=4, figsize=(10,6))\n",
        "\n",
        "    for i in range(0, 7):\n",
        "\n",
        "        # grid positions for the graph\n",
        "        xgrid = int(i%2)\n",
        "        ygrid = int(i/2)\n",
        "\n",
        "        ################################################################\n",
        "        # CV's distribution comparison\n",
        "        ################################################################\n",
        "        plt.figure(1)\n",
        "        plt.subplot2grid((2,4),(xgrid,ygrid))\n",
        "        plt.title(lname[i])\n",
        "\n",
        "        # excluding NAN values\n",
        "        aux1 = measures_less.groupby('layer')['cv_less'].get_group(lname[i])\n",
        "        aux1 = aux1[~np.isnan(aux1)]\n",
        "\n",
        "        aux2 = measures_default.groupby('layer')['cv_default'].get_group(lname[i])\n",
        "        aux2 = aux2[~np.isnan(aux2)]\n",
        "\n",
        "        # CV's histograms\n",
        "        cv1,edges1 = np.histogram(aux1,bins='sqrt',range=(0,2.0))\n",
        "        cv2,edges2 = np.histogram(aux2,bins=np.linspace(0,2.0,len(edges1)))\n",
        "\n",
        "        # cummulated histograms\n",
        "        cv1 = np.cumsum(cv1)\n",
        "        cv2 = np.cumsum(cv2)\n",
        "\n",
        "        # normalizing cummulated histograms\n",
        "        cv1 = cv1/float(max(cv1))\n",
        "        cv2 = cv2/float(max(cv2))\n",
        "\n",
        "        # plot data\n",
        "        plt.plot(edges1[:-1],cv1,'--', label=f'{scale * 100}% neurons')\n",
        "        plt.plot(edges2[:-1],cv2,label='All neurons')\n",
        "        if (i==0): plt.legend(loc=4)\n",
        "        if (i>1): plt.yticks([])\n",
        "        if (i%2==0): plt.xticks([])\n",
        "        plt.autoscale(enable=True, axis='x', tight=True)\n",
        "\n",
        "        # Kolmogorov-Smirnov statistical test\n",
        "        ks_cv[i], p_cv[i] = ks_2samp(cv1, cv2)\n",
        "\n",
        "        del aux1, aux2, cv1, cv2\n",
        "\n",
        "        ################################################################\n",
        "        # firing rate distribution comparison\n",
        "        ################################################################\n",
        "        plt.figure(2)\n",
        "        plt.subplot2grid((2,4),(xgrid,ygrid))\n",
        "        plt.title(lname[i])\n",
        "\n",
        "        # excluding NAN values\n",
        "        aux1 = measures_less.groupby('layer')['f_less'].get_group(lname[i])\n",
        "        aux1 = aux1[~np.isnan(aux1)]\n",
        "\n",
        "        aux2 = measures_default.groupby('layer')['f_default'].get_group(lname[i])\n",
        "        aux2 = aux2[~np.isnan(aux2)]\n",
        "\n",
        "        # firing rate histograms\n",
        "        f1,edges1 = np.histogram(aux1,bins='sqrt',range=(0,max(aux1)))\n",
        "        f2,edges2 = np.histogram(aux2,bins=np.linspace(0,max(aux1),len(edges1)))\n",
        "\n",
        "        # cummulated histograms\n",
        "        f1 = np.cumsum(f1)\n",
        "        f2 = np.cumsum(f2)\n",
        "\n",
        "        # normalizing cummulated histograms\n",
        "        f1 = f1/float(max(f1))\n",
        "        f2 = f2/float(max(f2))\n",
        "\n",
        "        # plot data\n",
        "        plt.plot(edges1[:-1],f1,'--', label=f'{scale * 100}% neurons')\n",
        "        plt.plot(edges1[:-1],f2,label='All neurons')\n",
        "        if (i==0): plt.legend(loc=4)\n",
        "        if (i>1): plt.yticks([])\n",
        "        plt.autoscale(enable=True, axis='x', tight=True)\n",
        "\n",
        "        # Kolmogorov-Smirnov statistical test\n",
        "        ks_f[i], p_f[i] = ks_2samp(f1, f2)\n",
        "\n",
        "        del aux1, aux2, f1, f2\n",
        "\n",
        "    # formating figures:ks_2samp\n",
        "    plt.figure(1)\n",
        "    fig1.add_subplot(111, frameon=False)\n",
        "    plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
        "    plt.xlabel('CV', fontsize=12, labelpad=10)\n",
        "    plt.ylabel('cumulative distribution',fontsize=12, labelpad=12)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.figure(2)\n",
        "    fig2.add_subplot(111, frameon=False)\n",
        "    plt.tick_params(labelcolor='none', top='off', bottom='off', left='off', right='off')\n",
        "    plt.xlabel('firing rate [Hz]', fontsize=12, labelpad=10)\n",
        "    plt.ylabel('cumulative distribution',fontsize=12, labelpad=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return ks_cv, ks_f, p_cv, p_f"
      ],
      "metadata": {
        "id": "rIox4rzdr0mY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks_cv, ks_f, p_cv, p_f = ks_test(tsim)"
      ],
      "metadata": {
        "id": "og_aUmDGwaMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the KS statistics\n",
        "print(f\"ks_cv={ks_cv}, ks_f={ks_f}\")\n",
        "print(f\"p_cv={p_cv}, p_f={p_f}\")"
      ],
      "metadata": {
        "id": "_bEFlQtyJpJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Less Neurons in the Network\n",
        "\n",
        "If we only use 95% of the original number of neurons, what would change? Let's run a simulation again and do a similar KS test and see what's happened."
      ],
      "metadata": {
        "id": "le3FCcy-IWR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layer = np.multiply([20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948, 902], 0.95).astype(int).tolist()\n",
        "N = sum(n_layer[:-1])\n",
        "nn_cum = [0]\n",
        "nn_cum.extend(cumsum(n_layer))\n",
        "\n",
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g = 4.0 # default value for inhibitory weight balance\n",
        "bg = 8.0 # default value for background rate\n",
        "\n",
        "bg_type = 0 # layer-specific inputs\n",
        "stim = 0 # Poissonian inputs\n",
        "tsim = 1 # time for simulation: 1 sec\n",
        "runParams(tsim=tsim, bg_type=bg_type, stim=stim, nsyn_type=0, filename=filename(g, bg, '_less'))\n",
        "gc.collect() #garbage collector to clean memory"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vLIWVfQoboau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# revert important parameters\n",
        "n_layer = [20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948, 902]\n",
        "N = sum(n_layer[:-1])\n",
        "nn_cum = [0]\n",
        "nn_cum.extend(cumsum(n_layer))"
      ],
      "metadata": {
        "id": "rV67YZEDHUWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks_cv, ks_f, p_cv, p_f = ks_test_n_neuron(tsim, scale=0.95)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0ujpmuoN3z8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the KS statistics\n",
        "print(f\"ks_cv={ks_cv}, ks_f={ks_f}\")\n",
        "print(f\"p_cv={p_cv}, p_f={p_f}\")"
      ],
      "metadata": {
        "id": "J-KuyDPcJvgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"green\">**To Do A2**</font> (1 point):\n",
        "1. Try to simulate using only 80% neurons and run a KS test. Are the changes more significant? Be careful: remember to revert the neuron numbers after your experiment since they are very important parameters."
      ],
      "metadata": {
        "id": "Ci6OsFq6QcLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##YOUR CODE##"
      ],
      "metadata": {
        "id": "y2OVJOAVRPcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**To Think A2**</font>:\n",
        "So far we have tinkered on two structural factors to \"slim\" down the network. Do those methods make the model better or worse in any sense? What do they help you understand more about the model (3 points)?"
      ],
      "metadata": {
        "id": "6Gslj5uqJy53"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYgySAN9kRZX"
      },
      "source": [
        "## The Asychronous Irregular (AI) Firing regime\n",
        "\n",
        "*Note*. Running this section may take >1 hour.\n",
        "\n",
        "The low-rate AI firing regime has been considered to be the ground state of cortical activity (Amit and Brunel 1997). And it might be related to the inhibitory weights and background rates. We can test it with our network by trying several inhibitory weights and background rates.\n",
        "\n",
        "To this end, we need to define a measure determining how AI a neuronal population is. We define AIness%, the percentage of populations with the firing rate <30 Hz, irregularity between 0.7 and 1.2, and synchrony <8, as a function of the background rate and the relative inhibitory synaptic strength.\n",
        "\n",
        "*Note*. We made some practical changes to this module. We deminished the number of simulations we need to do by testing less inhibitory weight and background rates values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ghtJHsGlsOlR"
      },
      "outputs": [],
      "source": [
        "#@title Plotting Functions: AI Firing Regime\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def datafig6(tsim):\n",
        "\n",
        "    g = np.arange(2.0,10.5,2);        # relative inh. synaptic strength values\n",
        "    bg_rate = np.arange(2.0,15.5,3);  # background rate values\n",
        "\n",
        "    ###############################################################################\n",
        "    # Parameters\n",
        "    ###############################################################################\n",
        "\n",
        "    # cortical layer labels: e for excitatory; i for inhibitory\n",
        "    lname = ['L23e', 'L23i', 'L4e', 'L4i', 'L5e', 'L5i','L6e', 'L6i']\n",
        "\n",
        "    # number of neurons by layer\n",
        "    n_layer = [0, 20683, 5834, 21915, 5479, 4850, 1065, 14395, 2948];\n",
        "    l_bins = np.cumsum(n_layer) # cumulative number of neurons by layer\n",
        "    N = np.sum(n_layer)         # total number of neurons\n",
        "\n",
        "    # creating dataframes to store measures\n",
        "    ainess = np.zeros((len(bg_rate),len(g))) # AIness index\n",
        "    freq_g4 = pd.DataFrame(index=lname)      # firing rates for g = 4.0\n",
        "    freq_bg8 = pd.DataFrame(index=lname)     # firing rates for bg = 8.0 Hz\n",
        "\n",
        "    for row in range(len(g)):\n",
        "        for col in range(len(bg_rate)):\n",
        "\n",
        "            # loading data to a DataFrame structure\n",
        "            filename = '../data/data_raster_g'+str(g[row])+'_bgrate'+str(bg_rate[col])+'.dat'\n",
        "            data = pd.read_csv(filename, sep=\" \", header=None, names=['i','t'])\n",
        "\n",
        "            # grouping spiking times for each neuron\n",
        "            keys,values = data.sort_values(['i','t']).values.T\n",
        "            ukeys,index=np.unique(keys,True)\n",
        "            arrays=np.split(values,index[1:])\n",
        "\n",
        "            spk_neuron = pd.DataFrame({'i':range(0,N),'t':[[]]*N})\n",
        "            # DEPRECATED: List of arrays cannot be directly assigned to dataframe\n",
        "            # spk_neuron.iloc[ukeys.astype(int),1] = arrays\n",
        "            for neuron_index, spike_times in zip(ukeys.astype(int), arrays):\n",
        "                spk_neuron.at[neuron_index, 't'] = spike_times.tolist()\n",
        "\n",
        "            # creating a flag to identify cortical layers\n",
        "            spk_neuron['layer'] = pd.cut(spk_neuron['i'], l_bins, labels=lname, right=False)\n",
        "            data['layer'] = pd.cut(data['i'], l_bins, labels=lname, right=False)\n",
        "\n",
        "            # sampling data\n",
        "            n_sample = 1000 # number of neurons by layer for sampled measures\n",
        "            spk_neuron = spk_neuron.groupby(['layer']).apply(lambda x: x.sample(n=n_sample))\n",
        "\n",
        "            # Reset the index to remove the ambiguity\n",
        "            spk_neuron = spk_neuron.reset_index(drop=True)\n",
        "\n",
        "            # measures DataFrame:\n",
        "            measures_layer = pd.DataFrame(index=lname)\n",
        "\n",
        "            # cleaning variables\n",
        "            del keys, values, ukeys, index, arrays\n",
        "\n",
        "            ########################################################################\n",
        "            # Mean firing rates\n",
        "            ########################################################################\n",
        "            freq = []\n",
        "            freq = [float(len(spk_neuron.t[i]))/tsim for i in range(len(spk_neuron))]\n",
        "            spk_neuron['f'] = freq\n",
        "\n",
        "            measures_layer['f'] = spk_neuron.groupby(['layer'])['f'].mean()\n",
        "\n",
        "            if g[row]==4.0: freq_g4[bg_rate[col]] = measures_layer.f\n",
        "            if bg_rate[col] == 8.0: freq_bg8[g[row]] = measures_layer.f\n",
        "\n",
        "            ########################################################################\n",
        "            # Interspike intervals + coefficient of variation\n",
        "            ########################################################################\n",
        "            # interspike intervals\n",
        "            isi = []\n",
        "            isi = [np.diff(spk_neuron.t[i]) for i in range(len(spk_neuron))]\n",
        "\n",
        "            # coefficient of variation\n",
        "            cv = []\n",
        "            cv = [np.std(isi[i])/np.mean(isi[i]) if len(isi[i])>1 else np.nan \\\n",
        "                    for i in range(len(spk_neuron))]\n",
        "            spk_neuron['cv'] = cv\n",
        "\n",
        "            measures_layer['cv'] = spk_neuron.groupby(['layer'])['cv'].mean()\n",
        "\n",
        "            ########################################################################\n",
        "            # Synchrony index\n",
        "            ########################################################################\n",
        "            sync = []\n",
        "            bins = np.arange(0,tsim*1000.0+3.0,3)\n",
        "\n",
        "            for i in range(len(lname)):\n",
        "                index_sample = spk_neuron.i[spk_neuron.layer.isin([lname[i]])]\n",
        "                count, division = np.histogram(data.t[data.i.isin(index_sample)],bins=bins)\n",
        "\n",
        "                # removing first 100 ms of simulation\n",
        "                sync.append(np.var(count[166:])/np.mean(count[166:]))\n",
        "\n",
        "            measures_layer['sync'] = sync\n",
        "\n",
        "            ########################################################################\n",
        "            # AIness measure: f<30Hz & 0.7<=cv<1.2 & sync_index <= 8\n",
        "            ########################################################################\n",
        "            measures_layer['AI'] = (measures_layer.f<30)&(measures_layer.sync<=8)&\\\n",
        "                                    (measures_layer.cv>=0.7)&(measures_layer.cv<1.2)\n",
        "\n",
        "            # % of layers in the AIness range\n",
        "            ainess[col][row] = 100*sum(measures_layer.AI)/8.0\n",
        "\n",
        "            # cleaning variables\n",
        "            del measures_layer, spk_neuron, data\n",
        "\n",
        "    # saving files\n",
        "    np.savetxt('../data/ainess.dat', ainess)\n",
        "    freq_g4.to_csv('../data/freq_g4.csv')\n",
        "    freq_bg8.to_csv('../data/freq_bg8.csv')\n",
        "\n",
        "\n",
        "def createfig6():\n",
        "\n",
        "    # loading data\n",
        "    data = pd.read_csv('../data/ainess.dat', header = None, sep=' ')\n",
        "    freq_g4 = pd.read_csv('../data/freq_g4.csv', index_col=0); freq_g4 = freq_g4.T\n",
        "    freq_bg8 = pd.read_csv('../data/freq_bg8.csv', index_col=0); freq_bg8 = freq_bg8.T\n",
        "\n",
        "    bg = np.arange(2.0,15.5,3)\n",
        "    g = np.arange(2,10.5,2)\n",
        "\n",
        "    plotstyle = ['-.','-^','-*','-s']\n",
        "\n",
        "    # figure size for the graphs\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    gs = gridspec.GridSpec(2, 3, width_ratios=[1, 3, 0.2], height_ratios=[3, 1])\n",
        "\n",
        "    # fig. 8A: firing rates for fixed parameter g = 4.0\n",
        "    ax1 = plt.subplot(gs[0,0])\n",
        "    plt.plot(freq_g4.L23e,bg, plotstyle[0])\n",
        "    plt.plot(freq_g4.L4e,bg, plotstyle[1])\n",
        "    plt.plot(freq_g4.L5e,bg, plotstyle[2])\n",
        "    plt.plot(freq_g4.L6e,bg, plotstyle[3])\n",
        "    plt.ylim([2,15])\n",
        "    plt.gca().invert_xaxis()\n",
        "    plt.xlabel('firing rate [Hz]')\n",
        "    plt.xlim(16, 0)\n",
        "\n",
        "    # fig. 8C: firing rates for fixed parameter background rate = 8.0Hz\n",
        "    ax2 = plt.subplot(gs[1,1])\n",
        "    freq_bg8.plot(y=['L23e','L4e','L5e','L6e'], ax=ax2, style=plotstyle)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.ylabel('firing rate [Hz]')\n",
        "\n",
        "    # fig. 8B: contour plot for %AIness\n",
        "    data = data.sort_index(ascending=False)\n",
        "    bg = np.arange(15.5,2.0,-3)\n",
        "\n",
        "    ax3 = plt.subplot(gs[0,1])\n",
        "    levels1 = np.linspace(0, 100, num=5, endpoint='True')\n",
        "    CS1 = plt.contour(g, bg, data, levels=levels1, colors='k', linestyles='dashed')\n",
        "    plt.clabel(CS1, inline=1, fontsize=10, fmt='%1.0f')\n",
        "    CS2 = plt.imshow(data, extent=[2,10,2,15], cmap='jet', interpolation='gaussian', aspect='auto')\n",
        "\n",
        "    plt.xlabel('relative inh. synaptic strength')\n",
        "    plt.ylabel('background rate [Hz]')\n",
        "\n",
        "    # colorbar of contour plot\n",
        "    ax4 = plt.subplot(gs[0,2])\n",
        "    plt.colorbar(CS2, cax=ax4, ticks=np.arange(0,101,50))\n",
        "    plt.title('%AIness')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HueH5rdvH9M"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/spike_network/code\n",
        "\n",
        "g_values = np.arange(2.0, 11.0, 2);  # relative inh. synaptic strength values\n",
        "bg_values = np.arange(2.0, 15.5, 3);  # background rate values\n",
        "\n",
        "bg_type = 0\n",
        "stim = 0\n",
        "tsim = 1\n",
        "\n",
        "for g in g_values:\n",
        "    for bg in bg_values:\n",
        "        runParams(tsim=tsim, bg_type=bg_type, stim=stim, g=g, \\\n",
        "        bg_freq=bg, filename=filename(g, bg))\n",
        "        gc.collect()    #garbage collector to clean memory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datafig6(tsim)\n",
        "createfig6()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e5TH8CK2kaCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**To Think A3**</font>\n",
        "\n",
        "1. To achieve sufficient AIness in sponetaneous activity, how should be inhibitory weights and background rates be tuned? What knowledge about the network mechanism can you gain from this experiment? (2 points)\n",
        "\n",
        "2. What can you do with this network? Provide a research question and desribe how you going to tackle it with this network. (2 points)\n",
        "\n",
        "3. What are you still not satisfied with this network? Desribe one limitation of this network. (1 point)"
      ],
      "metadata": {
        "id": "Aifcw9KsbTru"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}